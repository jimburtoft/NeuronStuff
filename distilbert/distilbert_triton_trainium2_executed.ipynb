{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DistilBERT Inference on AWS Trainium2 with Triton Inference Server\n",
    "\n",
    "This notebook deploys DistilBERT (`distilbert-base-uncased`) on an AWS **trn2.3xlarge** instance using\n",
    "NVIDIA Triton Inference Server with the AWS Neuron SDK, then benchmarks throughput and latency.\n",
    "\n",
    "Everything is self-contained: the notebook writes all required files (Dockerfile, Triton config,\n",
    "Python backend, compile script, benchmark client), builds the Docker image, compiles the models,\n",
    "starts the server, and runs the benchmark.\n",
    "\n",
    "**Instance**: trn2.3xlarge (1 Neuron device, 4 logical NeuronCores at LNC=2)  \n",
    "**Time to complete**: ~30 minutes (Docker build dominates)  \n",
    "**Prerequisites**: Deep Learning AMI Neuron (Ubuntu 24.04), Docker installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "We measure throughput (inferences/second) and latency (P50, P95, P99) under multiple load patterns,\n",
    "varying both client-side batch size and request concurrency to exercise Triton's dynamic batching.\n",
    "\n",
    "- **Input**: Fixed \"hello world\" text, tokenized and padded to 128 tokens\n",
    "- **Output**: 768-dimensional CLS token embedding (float32)\n",
    "- **Duration**: 10 seconds per test configuration\n",
    "- **Warmup**: 5 requests before timing\n",
    "- **Concurrency**: Python threads, one HTTP client per thread\n",
    "\n",
    "### Neuron-Specific: Per-Batch-Size Compilation\n",
    "\n",
    "Unlike GPUs, Neuron models are compiled for a **fixed batch size**. Running a BS=1 request through\n",
    "a BS=16 compiled model wastes 15/16 of the compute. We compile separate models for BS=1, 2, 4, 8, 16\n",
    "and the Triton Python backend dispatches each request to the smallest model that fits.\n",
    "\n",
    "### Triton Configuration\n",
    "\n",
    "- **4 model instances** (one per logical NeuronCore), each pinned via `NEURON_RT_VISIBLE_CORES`\n",
    "- **Dynamic batching**: preferred sizes [4, 8, 16], max queue delay 5ms\n",
    "- **Python backend**: Triton has no native Neuron backend, so we use the Python backend with `torch_neuronx`\n",
    "\n",
    "### Test Matrix\n",
    "\n",
    "| Test | Concurrency | Client Batch Sizes |\n",
    "|------|-------------|--------------------|\n",
    "| Baseline | 1 (no batching) | 1 |\n",
    "| Dynamic batching | 8, 16, 32 | 1, 2, 4, 8, 16 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model & Instance Specifications\n",
    "\n",
    "| Spec | Value |\n",
    "|------|-------|\n",
    "| Model | DistilBERT base uncased (67M params) |\n",
    "| Architecture | 6-layer transformer, hidden size 768 |\n",
    "| Input | 128 tokens (padded) |\n",
    "| Output | 768-dim float32 CLS embedding |\n",
    "| Compiled model size | ~468 MB per batch size variant |\n",
    "| Instance type | trn2.3xlarge |\n",
    "| Neuron device | 1 device, 8 physical NeuronCores |\n",
    "| LNC config | 2 (= 4 logical cores, 24 GB each) |\n",
    "| vCPUs / RAM | 12 / 128 GB |\n",
    "\n",
    "### Software Stack\n",
    "\n",
    "| Component | Version |\n",
    "|-----------|--------|\n",
    "| Neuron SDK | 2.27.1 |\n",
    "| PyTorch / torch-neuronx | 2.9.0 / 2.9.0.2.11 |\n",
    "| neuronx-cc (compiler) | 2.22.12471 |\n",
    "| Transformers | 4.48.0 |\n",
    "| Triton Inference Server | 2.65.0 (r26.01, built from source) |\n",
    "| Python | 3.12 |\n",
    "| OS / AMI | Ubuntu 24.04 / Deep Learning AMI Neuron 20260126 |\n",
    "\n",
    "> **Important**: Transformers versions 4.54.0+ have a confirmed 31% performance regression for\n",
    "> DistilBERT on Neuron. Use versions 4.48.0 through 4.53.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: Setup & Environment Check\n",
    "\n",
    "After you deploy the instance using the Ubuntu Neuron Deep Learning AMI (with all the Neuron drivers installed), run this notebook inside the pre-installed PyTorch 2.9 Neuron virtual environment:\n",
    "\n",
    "```bash\n",
    "source /opt/aws_neuronx_venv_pytorch_2_9\n",
    "pip install jupyter\n",
    "jupyter notebook --ip=0.0.0.0 --no-browser\n",
    "```\n",
    "\n",
    "Alternatively, if you are running from withing a remote vscode instance, you can use ```ln -s /opt/aws_neuronx_venv_pytorch_2_9/bin/activate ~/.venv``` to help vscode find your kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T04:43:07.303255Z",
     "iopub.status.busy": "2026-02-24T04:43:07.303093Z",
     "iopub.status.idle": "2026-02-24T04:46:49.665042Z",
     "shell.execute_reply": "2026-02-24T04:46:49.664396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.9.0+cu128\n",
      "torch-neuronx: 2.9.0.2.11.19912+e48cd891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "instance-type: trn2.3xlarge\n",
      "instance-id: i-06b73b69bde388511\n",
      "logical-neuroncore-config: 2\n",
      "+--------+--------+----------+--------+--------------+----------+------+\n",
      "| NEURON | NEURON |  NEURON  | NEURON |     PCI      |   CPU    | NUMA |\n",
      "| DEVICE | CORES  | CORE IDS | MEMORY |     BDF      | AFFINITY | NODE |\n",
      "+--------+--------+----------+--------+--------------+----------+------+\n",
      "| 0      | 4      | 0-3      | 96 GB  | 0000:33:00.0 | 0-11     | 0    |\n",
      "+--------+--------+----------+--------+--------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess, sys, os, time, shutil\n",
    "\n",
    "# Verify Neuron environment\n",
    "import torch, torch_neuronx\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "print(f'torch-neuronx: {torch_neuronx.__version__}')\n",
    "\n",
    "# Ensure correct transformers version\n",
    "try:\n",
    "    import transformers\n",
    "    ver = transformers.__version__\n",
    "    print(f'transformers: {ver}')\n",
    "    if ver >= '4.54.0':\n",
    "        print('WARNING: transformers >= 4.54.0 has 31% regression. Downgrading...')\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install',\n",
    "                               'transformers==4.48.0', '-q'])\n",
    "except ImportError:\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install',\n",
    "                           'transformers==4.48.0', '-q'])\n",
    "\n",
    "# Install Triton client\n",
    "subprocess.check_call([sys.executable, '-m', 'pip', 'install',\n",
    "                       'tritonclient[http]', '-q'])\n",
    "\n",
    "# Show Neuron devices\n",
    "r = subprocess.run(['neuron-ls'], capture_output=True, text=True)\n",
    "print(f'\\n{r.stdout}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Compile DistilBERT for All Batch Sizes\n",
    "\n",
    "Compile 5 model variants (BS=1, 2, 4, 8, 16) with sequence length 128 and LNC=2.\n",
    "Takes ~5 minutes per variant (~25 min total--time may vary for other models). Skips already-compiled models, so if you are running this multiple times you will see faster compilation.  For production, you would deploy with the pre-compiled models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T04:46:49.666593Z",
     "iopub.status.busy": "2026-02-24T04:46:49.666296Z",
     "iopub.status.idle": "2026-02-24T04:50:24.949590Z",
     "shell.execute_reply": "2026-02-24T04:50:24.948806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1b1c82e70e490ba7d7d52b906ce055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edfc32ef8c644a9c93613f370516acd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe653255a45e4222af96fcd232a457bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5631af596d5e4673a48cb787554c2dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dff613ae5484dd5a9b56c17e6a33d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling DistilBERT for batch sizes: [1, 2, 4, 8, 16]\n",
      "Sequence length: 128, LNC: 2\n",
      "\n",
      "  Compiling BS=1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed run_backend_driver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compiler status PASS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved: /home/ubuntu/triton_repo/distilbert/1/model_bs1.pt (468.1 MB)\n",
      "  Compiling BS=2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed run_backend_driver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compiler status PASS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved: /home/ubuntu/triton_repo/distilbert/1/model_bs2.pt (468.1 MB)\n",
      "  Compiling BS=4...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed run_backend_driver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compiler status PASS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved: /home/ubuntu/triton_repo/distilbert/1/model_bs4.pt (468.1 MB)\n",
      "  Compiling BS=8...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed run_backend_driver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compiler status PASS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved: /home/ubuntu/triton_repo/distilbert/1/model_bs8.pt (468.2 MB)\n",
      "  Compiling BS=16...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed run_backend_driver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compiler status PASS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved: /home/ubuntu/triton_repo/distilbert/1/model_bs16.pt (468.8 MB)\n",
      "\n",
      "Compiled models:\n",
      "  model_bs1.pt: 468.1 MB\n",
      "  model_bs16.pt: 468.8 MB\n",
      "  model_bs2.pt: 468.1 MB\n",
      "  model_bs4.pt: 468.1 MB\n",
      "  model_bs8.pt: 468.2 MB\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "\n",
    "os.environ['NEURON_RT_LOG_LEVEL'] = 'ERROR'\n",
    "\n",
    "SEQ_LENGTH = 128\n",
    "LNC = 2\n",
    "MODEL_DIR = os.path.expanduser('~/triton_repo/distilbert/1')\n",
    "BATCH_SIZES = [1, 2, 4, 8, 16]\n",
    "\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "model.eval()\n",
    "\n",
    "print(f'Compiling DistilBERT for batch sizes: {BATCH_SIZES}')\n",
    "print(f'Sequence length: {SEQ_LENGTH}, LNC: {LNC}\\n')\n",
    "\n",
    "for bs in BATCH_SIZES:\n",
    "    output_path = os.path.join(MODEL_DIR, f'model_bs{bs}.pt')\n",
    "    if os.path.exists(output_path):\n",
    "        print(f'  BS={bs}: already compiled, skipping')\n",
    "        continue\n",
    "    print(f'  Compiling BS={bs}...')\n",
    "    texts = ['Test sentence.'] * bs\n",
    "    inputs = tokenizer(texts, return_tensors='pt', max_length=SEQ_LENGTH,\n",
    "                       padding='max_length', truncation=True)\n",
    "    model_neuron = torch_neuronx.trace(\n",
    "        model, (inputs['input_ids'], inputs['attention_mask']),\n",
    "        compiler_args=['--model-type', 'transformer', '--optlevel', '2',\n",
    "                       '--lnc', str(LNC)])\n",
    "    torch.jit.save(model_neuron, output_path)\n",
    "    size_mb = os.path.getsize(output_path) / (1024 * 1024)\n",
    "    print(f'    Saved: {output_path} ({size_mb:.1f} MB)')\n",
    "\n",
    "print('\\nCompiled models:')\n",
    "for f in sorted(os.listdir(MODEL_DIR)):\n",
    "    if f.endswith('.pt'):\n",
    "        size = os.path.getsize(os.path.join(MODEL_DIR, f)) / (1024 * 1024)\n",
    "        print(f'  {f}: {size:.1f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Write Triton Model Repository Files\n",
    "\n",
    "Write `config.pbtxt` and `model.py` into the model repository alongside the compiled `.pt` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T04:50:24.951991Z",
     "iopub.status.busy": "2026-02-24T04:50:24.951655Z",
     "iopub.status.idle": "2026-02-24T04:50:24.957870Z",
     "shell.execute_reply": "2026-02-24T04:50:24.957008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote config.pbtxt\n",
      "Wrote model.py\n",
      "\n",
      "Model repository:\n",
      "triton_repo/\n",
      "  distilbert/\n",
      "    config.pbtxt\n",
      "    1/\n",
      "      model.py\n",
      "      model_bs1.pt (468.1 MB)\n",
      "      model_bs16.pt (468.8 MB)\n",
      "      model_bs2.pt (468.1 MB)\n",
      "      model_bs4.pt (468.1 MB)\n",
      "      model_bs8.pt (468.2 MB)\n"
     ]
    }
   ],
   "source": [
    "REPO_DIR = os.path.expanduser('~/triton_repo/distilbert')\n",
    "\n",
    "# ── config.pbtxt ──────────────────────────────────────────────────────────────\n",
    "config_pbtxt = r\"\"\"name: \"distilbert\"\n",
    "platform: \"python\"\n",
    "backend: \"python\"\n",
    "max_batch_size: 16\n",
    "\n",
    "input [\n",
    "  {\n",
    "    name: \"input_ids\"\n",
    "    data_type: TYPE_INT64\n",
    "    dims: [128]\n",
    "  },\n",
    "  {\n",
    "    name: \"attention_mask\"\n",
    "    data_type: TYPE_INT64\n",
    "    dims: [128]\n",
    "  }\n",
    "]\n",
    "\n",
    "output [\n",
    "  {\n",
    "    name: \"embeddings\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [768]\n",
    "  }\n",
    "]\n",
    "\n",
    "instance_group [\n",
    "  {\n",
    "    count: 4\n",
    "    kind: KIND_CPU\n",
    "  }\n",
    "]\n",
    "\n",
    "dynamic_batching {\n",
    "  preferred_batch_size: [4, 8, 16]\n",
    "  max_queue_delay_microseconds: 5000\n",
    "}\n",
    "\n",
    "parameters: {\n",
    "  key: \"model_dir\"\n",
    "  value: { string_value: \"/models/distilbert/1\" }\n",
    "}\n",
    "\n",
    "parameters: {\n",
    "  key: \"tokenizer_name\"\n",
    "  value: { string_value: \"distilbert-base-uncased\" }\n",
    "}\n",
    "\n",
    "parameters: {\n",
    "  key: \"max_seq_length\"\n",
    "  value: { string_value: \"128\" }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join(REPO_DIR, 'config.pbtxt'), 'w') as f:\n",
    "    f.write(config_pbtxt)\n",
    "print('Wrote config.pbtxt')\n",
    "\n",
    "# ── model.py (Triton Python backend) ──────────────────────────────────────────\n",
    "model_py = r'''#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Triton Python Backend for DistilBERT on AWS Neuron - Multi-Model\n",
    "\n",
    "Loads compiled models for each batch size (1, 2, 4, 8, 16) and\n",
    "dispatches to the best-fit model to avoid padding waste.\n",
    "Each Triton instance is pinned to a separate Neuron core.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import triton_python_backend_utils as pb_utils\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import torch\n",
    "import torch_neuronx\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "\n",
    "class TritonPythonModel:\n",
    "    BATCH_SIZES = [1, 2, 4, 8, 16]\n",
    "\n",
    "    def initialize(self, args):\n",
    "        self.model_config = json.loads(args[\"model_config\"])\n",
    "        params = self.model_config.get(\"parameters\", {})\n",
    "        model_dir = params.get(\"model_dir\", {}).get(\n",
    "            \"string_value\", \"/models/distilbert/1\")\n",
    "        tokenizer_name = params.get(\"tokenizer_name\", {}).get(\n",
    "            \"string_value\", \"distilbert-base-uncased\")\n",
    "        self.max_seq_length = int(\n",
    "            params.get(\"max_seq_length\", {}).get(\"string_value\", \"128\"))\n",
    "\n",
    "        # Pin this instance to a specific Neuron core\n",
    "        instance_name = args.get(\"model_instance_name\", \"distilbert_0_0\")\n",
    "        core_id = int(instance_name.split(\"_\")[-1])\n",
    "        os.environ[\"NEURON_RT_VISIBLE_CORES\"] = str(core_id)\n",
    "        os.environ[\"NEURON_LOGICAL_NC_CONFIG\"] = \"2\"\n",
    "        print(f\"Instance {instance_name}: pinned to Neuron core {core_id}\")\n",
    "\n",
    "        self.tokenizer = DistilBertTokenizer.from_pretrained(tokenizer_name)\n",
    "        print(\"Tokenizer loaded\")\n",
    "\n",
    "        # Load all compiled models\n",
    "        self.models = {}\n",
    "        for bs in self.BATCH_SIZES:\n",
    "            model_path = os.path.join(model_dir, f\"model_bs{bs}.pt\")\n",
    "            if os.path.exists(model_path):\n",
    "                self.models[bs] = torch.jit.load(model_path)\n",
    "                self.models[bs].eval()\n",
    "                print(f\"  Loaded model for batch_size={bs}\")\n",
    "            else:\n",
    "                print(f\"  WARNING: Model not found: {model_path}\")\n",
    "\n",
    "        if not self.models:\n",
    "            raise RuntimeError(\"No compiled models found!\")\n",
    "\n",
    "        # Warmup all models\n",
    "        print(\"Warming up models...\")\n",
    "        for bs, mdl in self.models.items():\n",
    "            dummy_ids = torch.zeros((bs, self.max_seq_length), dtype=torch.long)\n",
    "            dummy_mask = torch.ones((bs, self.max_seq_length), dtype=torch.long)\n",
    "            with torch.no_grad():\n",
    "                for _ in range(3):\n",
    "                    _ = mdl(dummy_ids, dummy_mask)\n",
    "            print(f\"  Warmed up BS={bs}\")\n",
    "        print(f\"Model initialization complete! \"\n",
    "              f\"Available batch sizes: {sorted(self.models.keys())}\")\n",
    "\n",
    "    def _get_best_model(self, actual_batch_size):\n",
    "        for bs in self.BATCH_SIZES:\n",
    "            if bs >= actual_batch_size and bs in self.models:\n",
    "                return bs, self.models[bs]\n",
    "        largest = max(self.models.keys())\n",
    "        return largest, self.models[largest]\n",
    "\n",
    "    def execute(self, requests):\n",
    "        responses = []\n",
    "        for request in requests:\n",
    "            input_ids = torch.from_numpy(\n",
    "                pb_utils.get_input_tensor_by_name(request, \"input_ids\").as_numpy()\n",
    "            ).long()\n",
    "            attention_mask = torch.from_numpy(\n",
    "                pb_utils.get_input_tensor_by_name(request, \"attention_mask\").as_numpy()\n",
    "            ).long()\n",
    "\n",
    "            actual_bs = input_ids.shape[0]\n",
    "            target_bs, model = self._get_best_model(actual_bs)\n",
    "\n",
    "            # Pad to compiled batch size if needed\n",
    "            if actual_bs < target_bs:\n",
    "                pad = target_bs - actual_bs\n",
    "                input_ids = torch.cat([input_ids,\n",
    "                    torch.zeros((pad, input_ids.shape[1]), dtype=torch.long)], dim=0)\n",
    "                attention_mask = torch.cat([attention_mask,\n",
    "                    torch.zeros((pad, attention_mask.shape[1]), dtype=torch.long)], dim=0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids, attention_mask)\n",
    "\n",
    "            embeddings = outputs[\"last_hidden_state\"][:, 0, :].cpu().numpy()\n",
    "            embeddings = embeddings[:actual_bs, :]\n",
    "\n",
    "            output_tensor = pb_utils.Tensor(\"embeddings\",\n",
    "                                            embeddings.astype(np.float32))\n",
    "            responses.append(\n",
    "                pb_utils.InferenceResponse(output_tensors=[output_tensor]))\n",
    "        return responses\n",
    "\n",
    "    def finalize(self):\n",
    "        print(\"Finalizing DistilBERT model...\")\n",
    "        if hasattr(self, \"models\"):\n",
    "            for bs, mdl in self.models.items():\n",
    "                del mdl\n",
    "            self.models.clear()\n",
    "'''\n",
    "\n",
    "with open(os.path.join(MODEL_DIR, 'model.py'), 'w') as f:\n",
    "    f.write(model_py)\n",
    "print('Wrote model.py')\n",
    "\n",
    "# Verify\n",
    "print('\\nModel repository:')\n",
    "for root, dirs, files in os.walk(os.path.expanduser('~/triton_repo')):\n",
    "    level = root.replace(os.path.expanduser('~/triton_repo'), '').count(os.sep)\n",
    "    indent = '  ' * level\n",
    "    print(f'{indent}{os.path.basename(root)}/')\n",
    "    for f in sorted(files):\n",
    "        size = os.path.getsize(os.path.join(root, f)) / (1024 * 1024)\n",
    "        label = f'{f} ({size:.1f} MB)' if size > 1 else f\n",
    "        print(f'{indent}  {label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Build Triton + Neuron Docker Image\n",
    "\n",
    "Triton has no native Neuron backend, so we build Triton from source inside the AWS Neuron\n",
    "PyTorch inference base image. This takes **15-20 minutes** and produces a ~15.8 GB image.\n",
    "\n",
    "The cell skips the build if the image already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T04:50:24.959898Z",
     "iopub.status.busy": "2026-02-24T04:50:24.959750Z",
     "iopub.status.idle": "2026-02-24T05:03:00.779494Z",
     "shell.execute_reply": "2026-02-24T05:03:00.778809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Triton + Neuron Docker image (15-20 minutes)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build complete!\n",
      "IMAGE                             ID             DISK USAGE   CONTENT SIZE   EXTRA\n",
      "triton-neuron-distilbert:latest   93e285ee1873       24.1GB         7.82GB        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "DOCKER_IMAGE = 'triton-neuron-distilbert:latest'\n",
    "\n",
    "# Check if already built\n",
    "r = subprocess.run(['docker', 'images', '-q', DOCKER_IMAGE],\n",
    "                   capture_output=True, text=True)\n",
    "if r.stdout.strip():\n",
    "    print(f'Docker image already exists: {r.stdout.strip()}')\n",
    "    print('Delete with: docker rmi ' + DOCKER_IMAGE)\n",
    "else:\n",
    "    # Write Dockerfile\n",
    "    dockerfile = r\"\"\"ARG BASE_IMAGE=public.ecr.aws/neuron/pytorch-inference-neuronx:2.9.0-neuronx-py312-sdk2.27.1-ubuntu24.04\n",
    "FROM $BASE_IMAGE\n",
    "\n",
    "ENV DEBIAN_FRONTEND=noninteractive \\\n",
    "    PYTHONDONTWRITEBYTECODE=1 \\\n",
    "    PYTHONUNBUFFERED=1 \\\n",
    "    PJRT_DEVICE=NEURON \\\n",
    "    LD_LIBRARY_PATH=\"/opt/conda/lib:/opt/aws/neuron/lib:/lib/x86_64-linux-gnu:${LD_LIBRARY_PATH}\" \\\n",
    "    PATH=\"/opt/program:/opt/aws/neuron/bin:/opt/tritonserver/bin:${PATH}\"\n",
    "\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends \\\n",
    "    wget gnupg2 build-essential git nginx pkg-config unzip \\\n",
    "    libssl-dev libcurl4-openssl-dev libgoogle-perftools-dev \\\n",
    "    libnuma-dev libarchive-dev libxml2-dev zlib1g-dev \\\n",
    "    autoconf automake libtool gperf scons patchelf \\\n",
    "    libre2-dev libb64-dev rapidjson-dev libboost-dev \\\n",
    "    cmake cmake-data \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "RUN pip3 install --no-cache-dir --upgrade pip setuptools wheel virtualenv build cmake==3.31.10\n",
    "RUN pip3 install transformers==4.48.0\n",
    "\n",
    "RUN git clone --depth=1 --branch=r26.01 https://github.com/triton-inference-server/server.git /server && \\\n",
    "    cd /server && \\\n",
    "    Python3_ROOT_DIR=/opt/conda \\\n",
    "    Python3_EXECUTABLE=/opt/conda/bin/python3 \\\n",
    "    Python3_INCLUDE_DIR=/opt/conda/include/python3.12 \\\n",
    "    Python3_LIBRARY=/opt/conda/lib/libpython3.12.so \\\n",
    "    ./build.py -v --no-container-build --build-dir=/server/build --backend=python \\\n",
    "    --enable-metrics --enable-logging --enable-stats --endpoint=\"http\" --endpoint=\"grpc\" && \\\n",
    "    cp -r /server/build/opt/* /opt/ && \\\n",
    "    cd / && rm -rf /server\n",
    "\n",
    "EXPOSE 8000 8001 8002\n",
    "CMD [\"tritonserver\", \"--model-repository=/models\"]\n",
    "\"\"\"\n",
    "    dockerfile_path = os.path.expanduser('~/Dockerfile.triton-neuron')\n",
    "    with open(dockerfile_path, 'w') as f:\n",
    "        f.write(dockerfile)\n",
    "\n",
    "    print('Building Triton + Neuron Docker image (15-20 minutes)...')\n",
    "    r = subprocess.run(\n",
    "        ['docker', 'build', '-f', dockerfile_path, '-t', DOCKER_IMAGE, '.'],\n",
    "        cwd=os.path.expanduser('~'),\n",
    "        capture_output=True, text=True, timeout=2400)\n",
    "    if r.returncode == 0:\n",
    "        print('Build complete!')\n",
    "    else:\n",
    "        print(f'Build FAILED (rc={r.returncode})')\n",
    "        print(r.stderr[-3000:])\n",
    "\n",
    "# Show image\n",
    "r = subprocess.run(['docker', 'images', DOCKER_IMAGE], capture_output=True, text=True)\n",
    "print(r.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Start Triton Server\n",
    "\n",
    "Launch the Docker container with the Neuron device mounted and the model repository bind-mounted.\n",
    "Waits for the server to become ready (~60-90 seconds for model loading + warmup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T05:03:00.781317Z",
     "iopub.status.busy": "2026-02-24T05:03:00.781162Z",
     "iopub.status.idle": "2026-02-24T05:03:57.832637Z",
     "shell.execute_reply": "2026-02-24T05:03:57.832002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container started. Waiting for model loading (~60-90s)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server ready after ~48s\n",
      "Model instances initialized: 4/4\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "# Stop any previous run\n",
    "subprocess.run(['docker', 'rm', '-f', 'triton-distilbert'],\n",
    "               capture_output=True)\n",
    "time.sleep(3)\n",
    "\n",
    "cmd = [\n",
    "    'docker', 'run', '-d',\n",
    "    '--name', 'triton-distilbert',\n",
    "    '--device=/dev/neuron0',\n",
    "    '-v', os.path.expanduser('~/triton_repo') + ':/models:ro',\n",
    "    '-p', '8000:8000', '-p', '8001:8001', '-p', '8002:8002',\n",
    "    DOCKER_IMAGE,\n",
    "    'tritonserver', '--model-repository=/models', '--log-verbose=0',\n",
    "]\n",
    "r = subprocess.run(cmd, capture_output=True, text=True)\n",
    "if r.returncode != 0:\n",
    "    print(f'Failed to start container: {r.stderr}')\n",
    "else:\n",
    "    print('Container started. Waiting for model loading (~60-90s)...')\n",
    "\n",
    "# Poll for readiness\n",
    "for i in range(120):\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        resp = urllib.request.urlopen('http://localhost:8000/v2/health/ready', timeout=2)\n",
    "        if resp.status == 200:\n",
    "            elapsed = (i + 1) * 2\n",
    "            print(f'Server ready after ~{elapsed}s')\n",
    "            break\n",
    "    except Exception:\n",
    "        pass\n",
    "else:\n",
    "    print('Timeout waiting for server!')\n",
    "    r = subprocess.run(['docker', 'logs', '--tail', '30', 'triton-distilbert'],\n",
    "                       capture_output=True, text=True)\n",
    "    print(r.stdout)\n",
    "\n",
    "# Verify instances loaded\n",
    "r = subprocess.run(['docker', 'logs', 'triton-distilbert'],\n",
    "                   capture_output=True, text=True)\n",
    "n = r.stdout.count('Model initialization complete')\n",
    "print(f'Model instances initialized: {n}/4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Run Benchmark\n",
    "\n",
    "Runs the full test matrix: 1 baseline + 15 dynamic-batching configurations (3 concurrency levels\n",
    "x 5 batch sizes), 10 seconds each. Total runtime ~3 minutes.\n",
    "\n",
    "**Note**: One worker per test will print a harmless greenlet thread-switch error. This is a\n",
    "known cosmetic issue in `tritonclient` and does not affect results -- the remaining workers run fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T05:03:57.834092Z",
     "iopub.status.busy": "2026-02-24T05:03:57.833968Z",
     "iopub.status.idle": "2026-02-24T05:06:39.653052Z",
     "shell.execute_reply": "2026-02-24T05:06:39.652418Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISTILBERT TRITON BENCHMARK - Neuron (trn2.3xlarge)\n",
      "==========================================================================================\n",
      "\n",
      "Baseline: single request, no concurrency...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  P50: 7.68ms  Throughput: 130 inf/sec\n",
      "\n",
      "Concurrency=8:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  BS=1   P50=   7.66ms  P95=   9.82ms  P99=  10.16ms  Throughput=     909 inf/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  BS=2   P50=   3.59ms  P95=   5.22ms  P99=   5.66ms  Throughput=    3629 inf/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  BS=4   P50=   3.72ms  P95=   7.11ms  P99=   7.47ms  Throughput=    6012 inf/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  BS=8   P50=   8.63ms  P95=  13.34ms  P99=  14.36ms  Throughput=    6152 inf/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  BS=16  P50=  18.54ms  P95=  20.97ms  P99=  21.58ms  Throughput=    6234 inf/sec\n",
      "\n",
      "Concurrency=16:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  BS=1   P50=   6.46ms  P95=   9.77ms  P99=  10.39ms  Throughput=    2109 inf/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  BS=2   P50=   5.02ms  P95=   8.65ms  P99=   9.06ms  Throughput=    5189 inf/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  BS=4   P50=  11.00ms  P95=  14.45ms  P99=  15.50ms  Throughput=    5861 inf/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  BS=8   P50=  21.20ms  P95=  22.26ms  P99=  22.93ms  Throughput=    5909 inf/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  BS=16  P50=  40.09ms  P95=  43.60ms  P99=  44.28ms  Throughput=    6056 inf/sec\n",
      "\n",
      "Concurrency=32:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  BS=1   P50=   9.17ms  P95=  15.54ms  P99=  16.48ms  Throughput=    2934 inf/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  BS=2   P50=  11.03ms  P95=  17.12ms  P99=  18.15ms  Throughput=    5219 inf/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  BS=4   P50=  22.52ms  P95=  24.12ms  P99=  25.09ms  Throughput=    5622 inf/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  BS=8   P50=  43.32ms  P95=  44.93ms  P99=  45.78ms  Throughput=    5815 inf/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  BS=16  P50=  84.43ms  P95=  90.87ms  P99=  92.38ms  Throughput=    5929 inf/sec\n",
      "\n",
      "==========================================================================================\n",
      "Batch   Workers   Requests    P50 (ms)    P95 (ms)    P99 (ms)    Throughput     \n",
      "------------------------------------------------------------------------------------------\n",
      "1       1         1304        7.68        7.86        7.93        130            \n",
      "1       8         9102        7.66        9.82        10.16       909            \n",
      "2       8         18161       3.59        5.22        5.66        3629           \n",
      "4       8         15043       3.72        7.11        7.47        6012           \n",
      "8       8         7697        8.63        13.34       14.36       6152           \n",
      "16      8         3905        18.54       20.97       21.58       6234           \n",
      "1       16        21123       6.46        9.77        10.39       2109           \n",
      "2       16        25989       5.02        8.65        9.06        5189           \n",
      "4       16        14677       11.00       14.45       15.50       5861           \n",
      "8       16        7405        21.20       22.26       22.93       5909           \n",
      "16      16        3804        40.09       43.60       44.28       6056           \n",
      "1       32        29435       9.17        15.54       16.48       2934           \n",
      "2       32        26239       11.03       17.12       18.15       5219           \n",
      "4       32        14142       22.52       24.12       25.09       5622           \n",
      "8       32        7311        43.32       44.93       45.78       5815           \n",
      "16      32        3745        84.43       90.87       92.38       5929           \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "import tritonclient.http as httpclient\n",
    "import threading\n",
    "from queue import Queue\n",
    "\n",
    "TRITON_URL = 'localhost:8000'\n",
    "MODEL_NAME = 'distilbert'\n",
    "DURATION = 10.0  # seconds per test\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "\n",
    "def _worker(client, batch_size, duration_s, latencies_q, stop_evt):\n",
    "    sentences = ['hello world'] * batch_size\n",
    "    tokens = tok(sentences, max_length=128, padding='max_length',\n",
    "                 truncation=True, return_tensors='np')\n",
    "    ids_np = tokens['input_ids'].astype(np.int64)\n",
    "    mask_np = tokens['attention_mask'].astype(np.int64)\n",
    "    inp_ids = httpclient.InferInput('input_ids', ids_np.shape, 'INT64')\n",
    "    inp_mask = httpclient.InferInput('attention_mask', mask_np.shape, 'INT64')\n",
    "    inp_ids.set_data_from_numpy(ids_np)\n",
    "    inp_mask.set_data_from_numpy(mask_np)\n",
    "    t_end = time.time() + duration_s\n",
    "    while time.time() < t_end and not stop_evt.is_set():\n",
    "        try:\n",
    "            t0 = time.time()\n",
    "            client.infer(model_name=MODEL_NAME, inputs=[inp_ids, inp_mask])\n",
    "            latencies_q.put((time.time() - t0) * 1000)\n",
    "        except Exception:\n",
    "            break\n",
    "\n",
    "\n",
    "def run_concurrent(batch_size, num_workers, duration_s=DURATION):\n",
    "    clients = [httpclient.InferenceServerClient(url=TRITON_URL)\n",
    "               for _ in range(num_workers)]\n",
    "    # Warmup\n",
    "    tokens = tok(['hello world'] * batch_size, max_length=128,\n",
    "                 padding='max_length', truncation=True, return_tensors='np')\n",
    "    ids_np = tokens['input_ids'].astype(np.int64)\n",
    "    mask_np = tokens['attention_mask'].astype(np.int64)\n",
    "    inp_ids = httpclient.InferInput('input_ids', ids_np.shape, 'INT64')\n",
    "    inp_mask = httpclient.InferInput('attention_mask', mask_np.shape, 'INT64')\n",
    "    inp_ids.set_data_from_numpy(ids_np)\n",
    "    inp_mask.set_data_from_numpy(mask_np)\n",
    "    for _ in range(5):\n",
    "        clients[0].infer(model_name=MODEL_NAME, inputs=[inp_ids, inp_mask])\n",
    "\n",
    "    q = Queue()\n",
    "    stop = threading.Event()\n",
    "    threads = []\n",
    "    t_start = time.time()\n",
    "    for i in range(num_workers):\n",
    "        t = threading.Thread(target=_worker,\n",
    "                             args=(clients[i], batch_size, duration_s, q, stop))\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "    total_time = time.time() - t_start\n",
    "\n",
    "    latencies = []\n",
    "    while not q.empty():\n",
    "        latencies.append(q.get())\n",
    "    if not latencies:\n",
    "        return None\n",
    "    return {\n",
    "        'batch_size': batch_size, 'num_workers': num_workers,\n",
    "        'total_requests': len(latencies),\n",
    "        'p50': np.percentile(latencies, 50),\n",
    "        'p95': np.percentile(latencies, 95),\n",
    "        'p99': np.percentile(latencies, 99),\n",
    "        'throughput': (len(latencies) * batch_size) / total_time,\n",
    "    }\n",
    "\n",
    "\n",
    "def run_baseline(duration_s=DURATION):\n",
    "    client = httpclient.InferenceServerClient(url=TRITON_URL)\n",
    "    tokens = tok(['hello world'], max_length=128, padding='max_length',\n",
    "                 truncation=True, return_tensors='np')\n",
    "    ids_np = tokens['input_ids'].astype(np.int64)\n",
    "    mask_np = tokens['attention_mask'].astype(np.int64)\n",
    "    inp_ids = httpclient.InferInput('input_ids', ids_np.shape, 'INT64')\n",
    "    inp_mask = httpclient.InferInput('attention_mask', mask_np.shape, 'INT64')\n",
    "    inp_ids.set_data_from_numpy(ids_np)\n",
    "    inp_mask.set_data_from_numpy(mask_np)\n",
    "    for _ in range(10):\n",
    "        client.infer(model_name=MODEL_NAME, inputs=[inp_ids, inp_mask])\n",
    "    latencies = []\n",
    "    t_start = time.time()\n",
    "    while time.time() - t_start < duration_s:\n",
    "        t0 = time.time()\n",
    "        client.infer(model_name=MODEL_NAME, inputs=[inp_ids, inp_mask])\n",
    "        latencies.append((time.time() - t0) * 1000)\n",
    "    total_time = time.time() - t_start\n",
    "    return {\n",
    "        'batch_size': 1, 'num_workers': 1,\n",
    "        'total_requests': len(latencies),\n",
    "        'p50': np.percentile(latencies, 50),\n",
    "        'p95': np.percentile(latencies, 95),\n",
    "        'p99': np.percentile(latencies, 99),\n",
    "        'throughput': len(latencies) / total_time,\n",
    "    }\n",
    "\n",
    "\n",
    "# ── Run all tests ─────────────────────────────────────────────────────────────\n",
    "client = httpclient.InferenceServerClient(url=TRITON_URL)\n",
    "assert client.is_server_ready(), 'Triton server not ready!'\n",
    "\n",
    "print('DISTILBERT TRITON BENCHMARK - Neuron (trn2.3xlarge)')\n",
    "print('=' * 90)\n",
    "\n",
    "results = []\n",
    "\n",
    "# Baseline\n",
    "print('\\nBaseline: single request, no concurrency...')\n",
    "r = run_baseline()\n",
    "results.append(r)\n",
    "print(f'  P50: {r[\"p50\"]:.2f}ms  Throughput: {r[\"throughput\"]:.0f} inf/sec')\n",
    "\n",
    "# Dynamic batching\n",
    "for conc in [8, 16, 32]:\n",
    "    print(f'\\nConcurrency={conc}:')\n",
    "    for bs in [1, 2, 4, 8, 16]:\n",
    "        r = run_concurrent(bs, conc)\n",
    "        if r:\n",
    "            results.append(r)\n",
    "            print(f'  BS={bs:<3} P50={r[\"p50\"]:>7.2f}ms  '\n",
    "                  f'P95={r[\"p95\"]:>7.2f}ms  '\n",
    "                  f'P99={r[\"p99\"]:>7.2f}ms  '\n",
    "                  f'Throughput={r[\"throughput\"]:>8.0f} inf/sec')\n",
    "\n",
    "# Summary table\n",
    "print(f'\\n{\"=\" * 90}')\n",
    "print(f'{\"Batch\":<8}{\"Workers\":<10}{\"Requests\":<12}'\n",
    "      f'{\"P50 (ms)\":<12}{\"P95 (ms)\":<12}{\"P99 (ms)\":<12}{\"Throughput\":<15}')\n",
    "print('-' * 90)\n",
    "for r in results:\n",
    "    print(f'{r[\"batch_size\"]:<8}{r[\"num_workers\"]:<10}{r[\"total_requests\"]:<12}'\n",
    "          f'{r[\"p50\"]:<12.2f}{r[\"p95\"]:<12.2f}{r[\"p99\"]:<12.2f}'\n",
    "          f'{r[\"throughput\"]:<15.0f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T05:06:39.654349Z",
     "iopub.status.busy": "2026-02-24T05:06:39.654228Z",
     "iopub.status.idle": "2026-02-24T05:06:40.273532Z",
     "shell.execute_reply": "2026-02-24T05:06:40.272851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triton server stopped and removed.\n"
     ]
    }
   ],
   "source": [
    "subprocess.run(['docker', 'rm', '-f', 'triton-distilbert'], capture_output=True)\n",
    "print('Triton server stopped and removed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Results\n",
    "\n",
    "Results from two independent runs on separate trn2.3xlarge instances (verified reproducible within ~3%).\n",
    "\n",
    "### Baseline (no dynamic batching)\n",
    "\n",
    "| Batch | Workers | P50 (ms) | P95 (ms) | P99 (ms) | Throughput (inf/sec) |\n",
    "|-------|---------|----------|----------|----------|---------------------|\n",
    "| 1     | 1       | 7.61     | 7.87     | 7.98     | 132                  |\n",
    "\n",
    "### Dynamic Batching -- Concurrency = 8 (Recommended)\n",
    "\n",
    "| Batch | P50 (ms) | P95 (ms) | P99 (ms) | Throughput (inf/sec) |\n",
    "|-------|----------|----------|----------|---------------------|\n",
    "| 1     | 7.65     | 9.72     | 10.02    | 919                  |\n",
    "| 2     | 3.72     | 5.17     | 5.48     | 3,516                |\n",
    "| 4     | 3.66     | 7.03     | 7.25     | 5,980                |\n",
    "| 8     | 7.85     | 14.49    | 15.05    | 6,128                |\n",
    "| 16    | 19.18    | 21.24    | 21.61    | 6,194                |\n",
    "\n",
    "### Dynamic Batching -- Concurrency = 16\n",
    "\n",
    "| Batch | P50 (ms) | P95 (ms) | P99 (ms) | Throughput (inf/sec) |\n",
    "|-------|----------|----------|----------|---------------------|\n",
    "| 1     | 6.63     | 9.69     | 10.12    | 2,082                |\n",
    "| 2     | 5.03     | 8.73     | 9.15     | 5,075                |\n",
    "| 4     | 10.00    | 14.84    | 15.78    | 5,788                |\n",
    "| 8     | 21.45    | 22.42    | 23.08    | 5,851                |\n",
    "| 16    | 40.70    | 43.89    | 44.70    | 5,988                |\n",
    "\n",
    "### Dynamic Batching -- Concurrency = 32\n",
    "\n",
    "| Batch | P50 (ms) | P95 (ms) | P99 (ms) | Throughput (inf/sec) |\n",
    "|-------|----------|----------|----------|---------------------|\n",
    "| 1     | 9.35     | 15.96    | 16.93    | 2,860                |\n",
    "| 2     | 10.93    | 17.39    | 18.44    | 5,146                |\n",
    "| 4     | 22.58    | 24.10    | 25.09    | 5,618                |\n",
    "| 8     | 43.73    | 45.69    | 46.53    | 5,751                |\n",
    "| 16    | 86.18    | 91.11    | 92.85    | 5,836                |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings\n",
    "\n",
    "| Metric | Value | Configuration |\n",
    "|--------|-------|---------------|\n",
    "| Peak throughput | **6,194 inf/sec** | Concurrency=8, BS=16 |\n",
    "| Best latency-throughput tradeoff | **5,980 inf/sec @ 3.66ms P50** | Concurrency=8, BS=4 |\n",
    "| Lowest latency | **3.66ms P50** | Concurrency=8, BS=4 |\n",
    "| Baseline (single request) | **132 inf/sec @ 7.61ms** | No batching |\n",
    "\n",
    "**Concurrency=8 is optimal** (2 workers per NeuronCore). Higher concurrency increases latency\n",
    "without improving throughput.\n",
    "\n",
    "### Why Per-Batch-Size Compilation Matters\n",
    "\n",
    "Neuron models are compiled for a fixed batch size. A single BS=16 model forces every request to\n",
    "pad up to 16 items, wasting compute. Compiling separate models for each batch size and dispatching\n",
    "to the smallest fit eliminates this waste:\n",
    "\n",
    "| Batch | Single Model (BS=16 only) | Per-BS Models | Improvement |\n",
    "|-------|--------------------------|---------------|-------------|\n",
    "| 1     | 238 inf/s                | 919 inf/s     | **+286%**   |\n",
    "| 2     | 790 inf/s                | 3,516 inf/s   | **+345%**   |\n",
    "| 4     | 1,575 inf/s              | 5,980 inf/s   | **+280%**   |\n",
    "| 8     | 3,085 inf/s              | 6,128 inf/s   | **+99%**    |\n",
    "| 16    | 6,130 inf/s              | 6,194 inf/s   | +1%         |\n",
    "\n",
    "At BS=16 both approaches are identical (same compiled model). At smaller batch sizes the\n",
    "improvement is 3-4x because inference time scales with the compiled batch size, not the\n",
    "actual number of items."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (aws_neuronx_venv_pytorch_2_9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0b48dc3764dd4ca380328968eda69f96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0e11e72dd5f94150809dc8a77fea3a44": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5d8c0b90c927498fa9f2428122a2f01a",
       "max": 48,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_661e5f79bf194555bf31cebb2ad05f88",
       "tabbable": null,
       "tooltip": null,
       "value": 48
      }
     },
     "1110afce87ee4e1c9825ae1aa57c5f20": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "15aacbd46e7c4927b66359804dc1f50f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1eef7ac83b604dc3891e9a7a07974d6d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2c36430e59f149a58ed21be02432a64e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "310b5b46364f4fd08e78426fb0d0235f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3519547538164bf2889c202d1d1eee57": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3fa8c1f846ef4636a7c9fc111096bc0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "40b930314e9040b2a5b2c1d907db9910": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "41cddea71e97416a9f96e3ff1cc6c69e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f925b2426ec04c4cb0beb5826824a03f",
       "placeholder": "​",
       "style": "IPY_MODEL_7751b5e129d647088a5c1af801661d6b",
       "tabbable": null,
       "tooltip": null,
       "value": " 232k/232k [00:00&lt;00:00, 1.10MB/s]"
      }
     },
     "4d86b2cddd1742fb9322b3695f0e263f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4e505b6c94da40cc97c501eb3339c3e2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "51c8fa0e5d5c454b906d6de2aac61580": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1110afce87ee4e1c9825ae1aa57c5f20",
       "placeholder": "​",
       "style": "IPY_MODEL_7aa5cccaf34242a293c4a97943db8b53",
       "tabbable": null,
       "tooltip": null,
       "value": " 266M/268M [00:01&lt;00:00, 622MB/s]"
      }
     },
     "5631af596d5e4673a48cb787554c2dfb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_aaabce9d74a447c58c53495dc75f2d2f",
        "IPY_MODEL_dbb9c4f88a6b41b4b86581f3f3d12f64",
        "IPY_MODEL_ab04a43201be4798a3402d61ef19f3cf"
       ],
       "layout": "IPY_MODEL_fc9c0fe3ce6140c7ac1bd9b214807fcd",
       "tabbable": null,
       "tooltip": null
      }
     },
     "57263e698e734212b4750f218497bbc9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5884cf7074de4e66a552a4ca6728dc77": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5d8c0b90c927498fa9f2428122a2f01a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "661e5f79bf194555bf31cebb2ad05f88": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "663891ded1f74950ad9a4f65f4552c2c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6639966cf1264c74917b33619651aed2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8f99ebefc9c94d3981f72a32db810ff7",
       "placeholder": "​",
       "style": "IPY_MODEL_0b48dc3764dd4ca380328968eda69f96",
       "tabbable": null,
       "tooltip": null,
       "value": " 466k/466k [00:00&lt;00:00, 789kB/s]"
      }
     },
     "6a2e24b48ad0440eb8a62a15e64841ae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6cf42b5a3cae4b4bb76ff3ef239d04ea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_40b930314e9040b2a5b2c1d907db9910",
       "placeholder": "​",
       "style": "IPY_MODEL_e307cc9d89fa40e4b93fc2fc303d409b",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors:  99%"
      }
     },
     "6e1efbcbf6df45f9b80f1aaa0454e145": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "746cadb5788b46428b11c47c363ec371": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7751b5e129d647088a5c1af801661d6b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7886f4e904c74df8aee4b4d679c25dbc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6e1efbcbf6df45f9b80f1aaa0454e145",
       "placeholder": "​",
       "style": "IPY_MODEL_3fa8c1f846ef4636a7c9fc111096bc0d",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "7aa5cccaf34242a293c4a97943db8b53": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7cc3fae8f57f4264a45ddd3abc39e85b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "82087b2c8ed5461798ff5a780b96f37b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8778ad0096314f97b50d1038007e2626": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8f99ebefc9c94d3981f72a32db810ff7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "947308b9c27c46d48a6d66146b6a4569": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9978b9970e2d4b3c86cf04014f58385a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9dff613ae5484dd5a9b56c17e6a33d6e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6cf42b5a3cae4b4bb76ff3ef239d04ea",
        "IPY_MODEL_9ee8e4de05274d60a81c447655ac376c",
        "IPY_MODEL_51c8fa0e5d5c454b906d6de2aac61580"
       ],
       "layout": "IPY_MODEL_b0702ad952ab42d39dae50a8565c9d7b",
       "tabbable": null,
       "tooltip": null
      }
     },
     "9ee8e4de05274d60a81c447655ac376c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2c36430e59f149a58ed21be02432a64e",
       "max": 267954768,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ca1fcb954e51442b9360015f9a8adae5",
       "tabbable": null,
       "tooltip": null,
       "value": 265598091
      }
     },
     "aaabce9d74a447c58c53495dc75f2d2f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_57263e698e734212b4750f218497bbc9",
       "placeholder": "​",
       "style": "IPY_MODEL_e724976db9374ae689eb66623685a7b4",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "ab04a43201be4798a3402d61ef19f3cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3519547538164bf2889c202d1d1eee57",
       "placeholder": "​",
       "style": "IPY_MODEL_7cc3fae8f57f4264a45ddd3abc39e85b",
       "tabbable": null,
       "tooltip": null,
       "value": " 483/483 [00:00&lt;00:00, 143kB/s]"
      }
     },
     "b0702ad952ab42d39dae50a8565c9d7b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bd66c76019944c52b1e96a826325a20a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "be1b1c82e70e490ba7d7d52b906ce055": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7886f4e904c74df8aee4b4d679c25dbc",
        "IPY_MODEL_0e11e72dd5f94150809dc8a77fea3a44",
        "IPY_MODEL_cbb189c074dc4dddaea5142abd4a2882"
       ],
       "layout": "IPY_MODEL_6a2e24b48ad0440eb8a62a15e64841ae",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ca1fcb954e51442b9360015f9a8adae5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "cbb189c074dc4dddaea5142abd4a2882": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8778ad0096314f97b50d1038007e2626",
       "placeholder": "​",
       "style": "IPY_MODEL_310b5b46364f4fd08e78426fb0d0235f",
       "tabbable": null,
       "tooltip": null,
       "value": " 48.0/48.0 [00:00&lt;00:00, 10.4kB/s]"
      }
     },
     "d1f2efecb26c4a31a9421fa591d3a76c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_debb2f3822ed4588a112164abd0190de",
       "placeholder": "​",
       "style": "IPY_MODEL_82087b2c8ed5461798ff5a780b96f37b",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer.json: 100%"
      }
     },
     "d42f0d6719f24022be2b112c1574b5ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_746cadb5788b46428b11c47c363ec371",
       "max": 466062,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5884cf7074de4e66a552a4ca6728dc77",
       "tabbable": null,
       "tooltip": null,
       "value": 466062
      }
     },
     "dbb9c4f88a6b41b4b86581f3f3d12f64": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1eef7ac83b604dc3891e9a7a07974d6d",
       "max": 483,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_663891ded1f74950ad9a4f65f4552c2c",
       "tabbable": null,
       "tooltip": null,
       "value": 483
      }
     },
     "dc6e8c8e9ad24fd4bf4c956b68d4144c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bd66c76019944c52b1e96a826325a20a",
       "max": 231508,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4d86b2cddd1742fb9322b3695f0e263f",
       "tabbable": null,
       "tooltip": null,
       "value": 231508
      }
     },
     "debb2f3822ed4588a112164abd0190de": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e307cc9d89fa40e4b93fc2fc303d409b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e724976db9374ae689eb66623685a7b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "edfc32ef8c644a9c93613f370516acd9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fda40a7a1ff54452aeb7eda8f4216e3f",
        "IPY_MODEL_dc6e8c8e9ad24fd4bf4c956b68d4144c",
        "IPY_MODEL_41cddea71e97416a9f96e3ff1cc6c69e"
       ],
       "layout": "IPY_MODEL_947308b9c27c46d48a6d66146b6a4569",
       "tabbable": null,
       "tooltip": null
      }
     },
     "f925b2426ec04c4cb0beb5826824a03f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fc9c0fe3ce6140c7ac1bd9b214807fcd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fda40a7a1ff54452aeb7eda8f4216e3f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_15aacbd46e7c4927b66359804dc1f50f",
       "placeholder": "​",
       "style": "IPY_MODEL_9978b9970e2d4b3c86cf04014f58385a",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "fe653255a45e4222af96fcd232a457bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d1f2efecb26c4a31a9421fa591d3a76c",
        "IPY_MODEL_d42f0d6719f24022be2b112c1574b5ac",
        "IPY_MODEL_6639966cf1264c74917b33619651aed2"
       ],
       "layout": "IPY_MODEL_4e505b6c94da40cc97c501eb3339c3e2",
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

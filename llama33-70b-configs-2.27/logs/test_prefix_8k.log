INFO 02-04 19:28:37 [__init__.py:43] Available plugins for group vllm.platform_plugins:
INFO 02-04 19:28:37 [__init__.py:45] - neuron -> vllm_neuron:register
INFO 02-04 19:28:37 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
INFO 02-04 19:28:37 [__init__.py:217] Platform plugin neuron is activated
INFO 02-04 19:28:39 [importing.py:44] Triton is installed but 0 active driver(s) found (expected 1). Disabling Triton to prevent runtime errors.
INFO 02-04 19:28:39 [importing.py:68] Triton not installed or not compatible; certain GPU-related functions will not be available.
Testing Llama 3.3 70B with PREFIX CACHING:
  Context length: 8192
  Batch size: 4
  Block size: 32
  PA num blocks: 2048

Initializing LLM with prefix caching...
INFO 02-04 19:28:39 [utils.py:253] non-default args: {'dtype': 'bfloat16', 'max_model_len': 8192, 'tensor_parallel_size': 64, 'block_size': 32, 'enable_prefix_caching': True, 'max_num_seqs': 4, 'disable_log_stats': True, 'num_gpu_blocks_override': 2048, 'additional_config': {'override_neuron_config': {'is_block_kv_layout': True, 'is_prefix_caching': True}}, 'model': 'models/Llama-3.3-70B-Instruct/'}
[2026-02-04 19:28:39] INFO platform.py:100: Applying Neuron config overrides
[2026-02-04 19:28:39] INFO platform.py:116: Neuron config overrides applied successfully
INFO 02-04 19:28:39 [model.py:514] Resolved architecture: LlamaForCausalLM
INFO 02-04 19:28:41 [scheduler.py:230] Chunked prefill is enabled with max_num_batched_tokens=8192.
[2026-02-04 19:28:41] INFO platform_overrides.py:22: Skipping attention head divisibility check for Neuron platform
[2026-02-04 19:28:41] INFO platform.py:149: Neuron OpenAI serving overrides applied successfully
[2026-02-04 19:28:41] INFO platform.py:215: Adding 1 to num_gpu_blocks_override (2048 -> 2049) to account for null block allocation
[2026-02-04 19:28:41] INFO platform.py:241: The custom Neuron scheduler will disable chunked prefill and schedule requests using the continuous batching mechanism, prioritizing prefill over decode.
[2026-02-04 19:28:41] INFO platform.py:254: Neuron custom scheduler default: max_num_batched_tokens set to 131072. Override with --max-num-batched-tokens if needed.
[2026-02-04 19:28:41] WARNING platform.py:280: Pin memory is not supported on Neuron.
[0;36m(EngineCore_DP0 pid=250618)[0;0m INFO 02-04 19:28:41 [core.py:93] Initializing a V1 LLM engine (v0.13.0) with config: model='models/Llama-3.3-70B-Instruct/', speculative_config=None, tokenizer='models/Llama-3.3-70B-Instruct/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=64, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cpu, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False), seed=0, served_model_name=models/Llama-3.3-70B-Instruct/, enable_prefix_caching=True, enable_chunked_prefill=False, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': None, 'compile_ranges_split_points': [8192], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.NONE: 0>, 'cudagraph_num_of_warmups': 0, 'cudagraph_capture_sizes': None, 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': None, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:42] INFO initializer.py:82: PJRT_DEVICE not set, defaulting to NEURON
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:16: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   from .mappings import (
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:16: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   from .mappings import (
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:16: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   from .mappings import (
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/modules/moe/blockwise.py:74: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   component, error = import_nki(config)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/modules/moe/blockwise.py:74: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   component, error = import_nki(config)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/modules/moe/blockwise.py:74: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   component, error = import_nki(config)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/modules/moe/blockwise.py:74: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   component, error = import_nki(config)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/bwmm_mxfp4.py:564: SyntaxWarning: assertion is always true, perhaps remove parentheses?
[0;36m(EngineCore_DP0 pid=250618)[0;0m   assert(token_indices_2D.shape==(128, 1), f"Expect token_indices_2D to have shape (128, 1), got {token_indices_2D.shape}")
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/modules/moe/blockwise.py:74: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   component, error = import_nki(config)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/modules/moe/blockwise.py:74: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   component, error = import_nki(config)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/modules/moe/blockwise.py:76: UserWarning: Warning: Failed to import blockwise_mm_baseline_shard_n_k1_while_2loops: No module named 'neuronxcc.nki._private.blockwise_matmul_while'
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(f"Warning: {error}")
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/modules/moe/moe_fused_tkg.py:49: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   component, error = import_nki(config)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/modules/moe/moe_fused_tkg.py:49: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   component, error = import_nki(config)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/modules/moe/moe_fused_tkg.py:49: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   component, error = import_nki(config)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/attention/utils.py:13: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   from neuronx_distributed_inference.modules.custom_calls import neuron_cumsum
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/lora_serving/lora_checkpoint.py:9: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   from neuronx_distributed_inference.modules.attention.gqa import replicate_kv
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/lora_serving/lora_checkpoint.py:9: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   from neuronx_distributed_inference.modules.attention.gqa import replicate_kv
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/lora_serving/lora_checkpoint.py:9: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   from neuronx_distributed_inference.modules.attention.gqa import replicate_kv
[0;36m(EngineCore_DP0 pid=250618)[0;0m WARNING 02-04 19:28:44 [interface.py:221] Failed to import from vllm._C: ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/models/dbrx/modeling_dbrx.py:38: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   from neuronx_distributed_inference.modules.attention.attention_base import NeuronAttentionBase
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/models/dbrx/modeling_dbrx.py:38: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   from neuronx_distributed_inference.modules.attention.attention_base import NeuronAttentionBase
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/models/dbrx/modeling_dbrx.py:38: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   from neuronx_distributed_inference.modules.attention.attention_base import NeuronAttentionBase
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/models/dbrx/modeling_dbrx.py:38: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   from neuronx_distributed_inference.modules.attention.attention_base import NeuronAttentionBase
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/utils/constants.py:1: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   from neuronx_distributed_inference.models.dbrx.modeling_dbrx import NeuronDbrxForCausalLM
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/models/llama4/modeling_llama4_vision.py:62: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   from neuronx_distributed_inference.models.mllama.modeling_mllama_vision import (
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/utils/constants.py:5: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   from neuronx_distributed_inference.models.mixtral.modeling_mixtral import NeuronMixtralForCausalLM
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/utils/constants.py:11: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   from neuronx_distributed_inference.models.qwen3_moe.modeling_qwen3_moe import NeuronQwen3MoeForCausalLM
[0;36m(EngineCore_DP0 pid=250618)[0;0m INFO 02-04 19:28:44 [parallel_state.py:1203] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://172.31.23.210:55283 backend=gloo
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[0;36m(EngineCore_DP0 pid=250618)[0;0m INFO 02-04 19:28:44 [parallel_state.py:1411] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=250618)[0;0m WARNING 02-04 19:28:44 [vllm.py:1403] Current vLLM config is not set.
[0;36m(EngineCore_DP0 pid=250618)[0;0m INFO 02-04 19:28:44 [scheduler.py:230] Chunked prefill is enabled with max_num_batched_tokens=2048.
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:44] INFO neuronx_distributed_model_loader.py:792: Retrieved override_neuron_config from additional_config: {'is_block_kv_layout': True, 'is_prefix_caching': True}
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:44] WARNING neuronx_distributed_model_loader.py:210: Exception: [Errno 2] No such file or directory: 'models/Llama-3.3-70B-Instruct/neuron-compiled-artifacts/6f506e1f43e8f0db867c03151462dc67/neuron_config.json'
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:44] WARNING neuronx_distributed_model_loader.py:211: Unable to find precompiled artifacts from models/Llama-3.3-70B-Instruct/neuron-compiled-artifacts/6f506e1f43e8f0db867c03151462dc67. Recompiling...
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:44] INFO model_wrapper.py:168: neuronx-cc compiler_args are: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true' 
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:44] INFO model_wrapper.py:168: neuronx-cc compiler_args are: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=1 --vectorize-strided-dma ' --lnc=2 -O2  --internal-hlo2tensorizer-options='--verify-hlo=true' 
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:44] INFO application_base.py:300: Saving the neuron_config to models/Llama-3.3-70B-Instruct/neuron-compiled-artifacts/6f506e1f43e8f0db867c03151462dc67/
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:45] INFO model_builder.py:549: Generating HLOs for the following models: ['context_encoding_model', 'token_generation_model']
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:45.465: I neuronx_distributed/parallel_layers/parallel_state.py:630] > initializing tensor model parallel with size 64
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:45.465: I neuronx_distributed/parallel_layers/parallel_state.py:631] > initializing pipeline model parallel with size 1
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:45.465: I neuronx_distributed/parallel_layers/parallel_state.py:632] > initializing context model parallel with size 1
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:45.465: I neuronx_distributed/parallel_layers/parallel_state.py:633] > initializing data parallel with size 1
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:45.466: I neuronx_distributed/parallel_layers/parallel_state.py:634] > initializing world size to 64
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:45.466: I neuronx_distributed/parallel_layers/parallel_state.py:379] [rank_0_pp-1_tp-1_dp-1_cp-1] Chosen Logic for replica groups ret_logic=<PG_Group_Logic.LOGIC1: (<function ascending_ring_PG_group at 0x7aed3f6a8b80>, 'Ascending Ring PG Group')>
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:45.467: I neuronx_distributed/parallel_layers/parallel_state.py:658] [rank_0_pp-1_tp-1_dp-1_cp-1] tp_groups: replica_groups.tp_groups=[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]]
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:45.467: I neuronx_distributed/parallel_layers/parallel_state.py:659] [rank_0_pp-1_tp-1_dp-1_cp-1] dp_groups: replica_groups.dp_groups=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63]]
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:45.467: I neuronx_distributed/parallel_layers/parallel_state.py:660] [rank_0_pp-1_tp-1_dp-1_cp-1] pp_groups: replica_groups.pp_groups=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63]]
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:45.468: I neuronx_distributed/parallel_layers/parallel_state.py:661] [rank_0_pp-1_tp-1_dp-1_cp-1] cp_groups: replica_groups.cp_groups=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63]]
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:45.468: I neuronx_distributed/parallel_layers/parallel_state.py:662] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_model_groups: replica_groups.ep_model_groups=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63]]
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:45.468: I neuronx_distributed/parallel_layers/parallel_state.py:663] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_data_groups: replica_groups.ep_data_groups=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63]]
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:45] INFO model_builder.py:575: Generating 30 hlos for key: context_encoding_model
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:45] INFO model_builder.py:929: Minimal metadata will be added to HLO
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:45] INFO model_builder.py:858: Started loading module context_encoding_model
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:45] INFO model_builder.py:861: Finished loading module context_encoding_model in 0.22710275650024414 seconds
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:45] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 512])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:51] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 5.789075136184692 seconds, input example shape = torch.Size([1, 512])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:51] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 512])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:54] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 3.027047634124756 seconds, input example shape = torch.Size([1, 512])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:54] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 512])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:234: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=250618)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:57] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 3.1452488899230957 seconds, input example shape = torch.Size([1, 512])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:28:57] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 512])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:234: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=250618)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:01] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 3.404805898666382 seconds, input example shape = torch.Size([1, 512])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:01] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 512])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:234: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=250618)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:05] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 4.29179835319519 seconds, input example shape = torch.Size([1, 512])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:05] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 512])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:234: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=250618)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:10] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 4.776355504989624 seconds, input example shape = torch.Size([1, 512])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:10] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 1024])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:12] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 2.757150650024414 seconds, input example shape = torch.Size([1, 1024])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:12] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 1024])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:16] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 3.2595369815826416 seconds, input example shape = torch.Size([1, 1024])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:16] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 1024])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=250618)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:20] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 3.8492510318756104 seconds, input example shape = torch.Size([1, 1024])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:20] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 1024])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=250618)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:23] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 3.611644983291626 seconds, input example shape = torch.Size([1, 1024])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:23] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 1024])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=250618)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:27] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 4.138934373855591 seconds, input example shape = torch.Size([1, 1024])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:27] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 1024])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=250618)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:32] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 4.926077365875244 seconds, input example shape = torch.Size([1, 1024])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:32] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 2048])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:36] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 3.344038963317871 seconds, input example shape = torch.Size([1, 2048])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:36] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 2048])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:39] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 3.672440528869629 seconds, input example shape = torch.Size([1, 2048])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:39] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 2048])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=250618)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:43] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 3.7663590908050537 seconds, input example shape = torch.Size([1, 2048])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:43] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 2048])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=250618)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:47] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 4.034832000732422 seconds, input example shape = torch.Size([1, 2048])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:47] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 2048])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=250618)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:51] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 4.363300561904907 seconds, input example shape = torch.Size([1, 2048])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:51] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 2048])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=250618)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:57] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 5.969402551651001 seconds, input example shape = torch.Size([1, 2048])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:29:57] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 4096])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:30:00] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 2.898104429244995 seconds, input example shape = torch.Size([1, 4096])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:30:00] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 4096])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:30:05] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 4.456584215164185 seconds, input example shape = torch.Size([1, 4096])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:30:05] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 4096])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=250618)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:30:09] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 4.585110425949097 seconds, input example shape = torch.Size([1, 4096])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:30:09] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 4096])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=250618)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:30:14] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 4.663518667221069 seconds, input example shape = torch.Size([1, 4096])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:30:14] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 4096])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=250618)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:30:20] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 5.9023449420928955 seconds, input example shape = torch.Size([1, 4096])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:30:20] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 4096])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=250618)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:30:26] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 6.555012941360474 seconds, input example shape = torch.Size([1, 4096])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:30:26] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 8192])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:30:30] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 3.1079630851745605 seconds, input example shape = torch.Size([1, 8192])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:30:30] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 8192])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:30:36] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 6.003082513809204 seconds, input example shape = torch.Size([1, 8192])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:30:36] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 8192])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=250618)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:30:42] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 6.907954692840576 seconds, input example shape = torch.Size([1, 8192])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:30:42] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 8192])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=250618)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:30:49] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 6.042436361312866 seconds, input example shape = torch.Size([1, 8192])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:30:49] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 8192])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=250618)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:30:56] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 7.220846891403198 seconds, input example shape = torch.Size([1, 8192])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:30:56] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 8192])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=250618)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:05] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 9.125030755996704 seconds, input example shape = torch.Size([1, 8192])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:05] INFO model_builder.py:575: Generating 6 hlos for key: token_generation_model
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:05] INFO model_builder.py:929: Minimal metadata will be added to HLO
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:05] INFO model_builder.py:858: Started loading module token_generation_model
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:05] INFO model_builder.py:861: Finished loading module token_generation_model in 0.2201223373413086 seconds
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:05] INFO model_builder.py:886: generating HLO: token_generation_model, input example shape = torch.Size([4, 1])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([4]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([4, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([4, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:09] INFO model_builder.py:900: Finished generating HLO for token_generation_model in 4.27313232421875 seconds, input example shape = torch.Size([4, 1])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:09] INFO model_builder.py:886: generating HLO: token_generation_model, input example shape = torch.Size([4, 1])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([4]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([4, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([4, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:13] INFO model_builder.py:900: Finished generating HLO for token_generation_model in 3.7096357345581055 seconds, input example shape = torch.Size([4, 1])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:13] INFO model_builder.py:886: generating HLO: token_generation_model, input example shape = torch.Size([4, 1])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([4]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([4, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([4, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:17] INFO model_builder.py:900: Finished generating HLO for token_generation_model in 3.7567245960235596 seconds, input example shape = torch.Size([4, 1])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:17] INFO model_builder.py:886: generating HLO: token_generation_model, input example shape = torch.Size([4, 1])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([4]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([4, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([4, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:21] INFO model_builder.py:900: Finished generating HLO for token_generation_model in 3.748621940612793 seconds, input example shape = torch.Size([4, 1])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:21] INFO model_builder.py:886: generating HLO: token_generation_model, input example shape = torch.Size([4, 1])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([4]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([4, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([4, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:24] INFO model_builder.py:900: Finished generating HLO for token_generation_model in 3.7728803157806396 seconds, input example shape = torch.Size([4, 1])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:24] INFO model_builder.py:886: generating HLO: token_generation_model, input example shape = torch.Size([4, 1])
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([4]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([4, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([4, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:28] INFO model_builder.py:900: Finished generating HLO for token_generation_model in 3.787400007247925 seconds, input example shape = torch.Size([4, 1])
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:28] INFO model_builder.py:600: Generated all HLOs in 163.45107340812683 seconds
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:28] INFO model_builder.py:632: Starting compilation for the priority HLO
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:28] INFO model_builder.py:635: 'token_generation_model' is the priority model with bucket rank 0
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:284: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(SyntaxWarning(
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:31:29.000382:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_8aa78293e4bb117ceb86+8f34053f/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:29] INFO model_builder.py:678: Done compilation for the priority HLO in 0.5785775184631348 seconds
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:29] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:30] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:30] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:31] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:32] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:33] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:33] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:34] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:35] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:35] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:36] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:37] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:38] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:38] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:39] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:40] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:41] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:42] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:43] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:44] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:44] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:45] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:47] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:48] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:49] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:50] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:52] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:53] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:55] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:57] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:58] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:58] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:59] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:31:59] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:00] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:00] INFO model_builder.py:1199: Done optimizing weight layout for all HLOs in 30.991289615631104 seconds
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:00] INFO model_builder.py:708: Starting compilation for all HLOs
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:00] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk0/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:246: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(SyntaxWarning(
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:01.000185:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_430ad9c4cfcb815fecd6+b35fee7e/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:01] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk1/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:01.000623:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_c9f1ec7c2b0a1e0d8d29+4e79e89b/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:01] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk2/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:02.000063:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_04390708a5c55ca3e2e3+3d4a12eb/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:02] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk3/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:02.000705:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_bbe16157363f6d5efbcc+8dd23d0c/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:02] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk4/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:03.000635:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_8e71ca9701a68b1efde5+42a8ac25/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:03] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk5/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:04] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk6/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:04.000468:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_20b012a3d350ab4411c4+0ba9c0cf/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:04.000483:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_4b82df2adcfa65a37032+1e783417/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:04] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk7/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:04.000935:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_7e37c1d7152a15b924e6+aef0bcf9/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:04] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk8/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:05.000438:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_3e7982a109ae1d0a0ca6+d0b40281/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:05] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk9/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:06.000068:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_0ca95d0b62233d2e7a36+5950f3a6/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:06] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk10/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:07.000089:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_9d994e6c81ba1ac91040+a1370a00/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:07] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk11/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:07] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk12/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:08.000005:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_75fd73fa876692ae2a17+ace07717/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:08.000016:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_cdd1387adae79229d921+adcca3dd/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:08] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk13/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:08.000570:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_2785dce72a76bc5e495a+c548991e/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:08] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk14/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:09.000175:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_ce24557923821f626259+b224735c/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:09] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk15/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:09.000899:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_ddb6f5e7f45672cbd232+61b0cb34/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:10] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk16/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:11.000050:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_5ba2f6bcdc8eff3c7897+58885c12/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:11] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk17/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:11] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk18/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:12.000403:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_dca8790d3bdfbefcf6e8+5584ed10/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:12.000422:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_3518666c2358bd8f48a9+70ad36f6/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:12] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk19/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:13.000215:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_7580b232a4cd5721568d+d1d18935/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:13] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk20/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:14.000026:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_76b9493b440b2a026a1d+1aa078d3/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:14] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk21/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:15.000146:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_608e6639273eed6cbce7+745dff57/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:15] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk22/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:16.000770:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_bc5a91f7abd67ec91420+2ac06b08/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:17] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk23/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:17] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk24/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:18.000644:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_0ac643736df7d46d7f9c+cf43e90b/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:18.000681:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_a4218beb17ddd55bb919+d6c0877f/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:18] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk25/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:20.000312:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_945f49e3ee1216bc560d+8705878f/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:20] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk26/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:21.000730:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_df51e696e606f8f4fe8a+48a4d7db/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:21] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk27/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:23.000289:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_e35669bc5e47db956d72+fb1a7077/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:23] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk28/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:25.000652:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_b476502d4e69c61ac3dd+045b3ada/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:26] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk29/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:26] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=1 --vectorize-strided-dma ' --lnc=2 -O2  --internal-hlo2tensorizer-options='--verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/token_generation_model/_tp0_bk1/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:26] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=1 --vectorize-strided-dma ' --lnc=2 -O2  --internal-hlo2tensorizer-options='--verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/token_generation_model/_tp0_bk2/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:27.000304:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_86fe006c7157712a2e12+057a5811/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:27] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=1 --vectorize-strided-dma ' --lnc=2 -O2  --internal-hlo2tensorizer-options='--verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/token_generation_model/_tp0_bk3/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:27] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=1 --vectorize-strided-dma ' --lnc=2 -O2  --internal-hlo2tensorizer-options='--verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/token_generation_model/_tp0_bk4/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:27.000932:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_f4f3682d68df1e4d98da+769d2bfd/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:27] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=1 --vectorize-strided-dma ' --lnc=2 -O2  --internal-hlo2tensorizer-options='--verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/token_generation_model/_tp0_bk5/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:27.000963:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_535a4cd1b67c65e9f395+610f5891/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:28.000007:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_6e2fd2e44aaeca8d5d13+d2076f45/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:28.000014:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_9893492373de6f1d63c5+ed5433ae/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m 2026-02-04 19:32:28.000183:  250618  [INFO]: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.22.12471.0+b4a00d10/MODULE_0ec766f5159931b73c15+2dad96a5/model.neff
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:32:31] INFO model_builder.py:760: Finished Compilation for all HLOs in 30.61025309562683 seconds
.....Completed run_backend_driver.

Compiler status PASS
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:33:57] INFO model_builder.py:1314: Done preparing weight layout transformation
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:33:57] INFO model_builder.py:783: Finished building model in 312.70306181907654 seconds
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:34:09] INFO application_base.py:249: SKIPPING pre-sharding the checkpoints. The checkpoints will be sharded during load time.
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:34:15] INFO application_base.py:404: Sharding weights on load...
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:34:15] INFO model_builder.py:808: Sharding weights for ranks: 0...63
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:34:15.507: I neuronx_distributed/parallel_layers/parallel_state.py:630] > initializing tensor model parallel with size 64
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:34:15.508: I neuronx_distributed/parallel_layers/parallel_state.py:631] > initializing pipeline model parallel with size 1
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:34:15.508: I neuronx_distributed/parallel_layers/parallel_state.py:632] > initializing context model parallel with size 1
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:34:15.508: I neuronx_distributed/parallel_layers/parallel_state.py:633] > initializing data parallel with size 1
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:34:15.508: I neuronx_distributed/parallel_layers/parallel_state.py:634] > initializing world size to 64
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:34:15.508: I neuronx_distributed/parallel_layers/parallel_state.py:379] [rank_0_pp-1_tp-1_dp-1_cp-1] Chosen Logic for replica groups ret_logic=<PG_Group_Logic.LOGIC1: (<function ascending_ring_PG_group at 0x7aed3f6a8b80>, 'Ascending Ring PG Group')>
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:34:15.609: I neuronx_distributed/parallel_layers/parallel_state.py:658] [rank_0_pp-1_tp-1_dp-1_cp-1] tp_groups: replica_groups.tp_groups=[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]]
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:34:15.610: I neuronx_distributed/parallel_layers/parallel_state.py:659] [rank_0_pp-1_tp-1_dp-1_cp-1] dp_groups: replica_groups.dp_groups=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63]]
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:34:15.610: I neuronx_distributed/parallel_layers/parallel_state.py:660] [rank_0_pp-1_tp-1_dp-1_cp-1] pp_groups: replica_groups.pp_groups=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63]]
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:34:15.610: I neuronx_distributed/parallel_layers/parallel_state.py:661] [rank_0_pp-1_tp-1_dp-1_cp-1] cp_groups: replica_groups.cp_groups=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63]]
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:34:15.610: I neuronx_distributed/parallel_layers/parallel_state.py:662] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_model_groups: replica_groups.ep_model_groups=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63]]
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:34:15.610: I neuronx_distributed/parallel_layers/parallel_state.py:663] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_data_groups: replica_groups.ep_data_groups=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63]]
[0;36m(EngineCore_DP0 pid=250618)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/trace/trace.py:642: UserWarning: Removing redundant keys from checkpoint: ['layers.49.self_attn.o_proj.weight', 'layers.50.self_attn.k_proj.weight', 'layers.50.self_attn.o_proj.weight', 'layers.50.self_attn.q_proj.weight', 'layers.50.self_attn.v_proj.weight', 'layers.51.self_attn.k_proj.weight', 'layers.51.self_attn.o_proj.weight', 'layers.51.self_attn.q_proj.weight', 'layers.51.self_attn.v_proj.weight', 'layers.38.self_attn.k_proj.weight', 'layers.38.self_attn.o_proj.weight', 'layers.38.self_attn.q_proj.weight', 'layers.38.self_attn.v_proj.weight', 'layers.39.self_attn.k_proj.weight', 'layers.39.self_attn.o_proj.weight', 'layers.39.self_attn.q_proj.weight', 'layers.39.self_attn.v_proj.weight', 'layers.40.self_attn.k_proj.weight', 'layers.40.self_attn.o_proj.weight', 'layers.40.self_attn.q_proj.weight', 'layers.40.self_attn.v_proj.weight', 'layers.0.self_attn.k_proj.weight', 'layers.0.self_attn.o_proj.weight', 'layers.0.self_attn.q_proj.weight', 'layers.0.self_attn.v_proj.weight', 'layers.1.self_attn.k_proj.weight', 'layers.1.self_attn.o_proj.weight', 'layers.1.self_attn.q_proj.weight', 'layers.1.self_attn.v_proj.weight', 'layers.21.self_attn.o_proj.weight', 'layers.22.self_attn.k_proj.weight', 'layers.22.self_attn.o_proj.weight', 'layers.22.self_attn.q_proj.weight', 'layers.22.self_attn.v_proj.weight', 'layers.23.self_attn.k_proj.weight', 'layers.23.self_attn.o_proj.weight', 'layers.23.self_attn.q_proj.weight', 'layers.23.self_attn.v_proj.weight', 'layers.33.self_attn.k_proj.weight', 'layers.33.self_attn.o_proj.weight', 'layers.33.self_attn.q_proj.weight', 'layers.33.self_attn.v_proj.weight', 'layers.34.self_attn.k_proj.weight', 'layers.34.self_attn.o_proj.weight', 'layers.34.self_attn.q_proj.weight', 'layers.34.self_attn.v_proj.weight', 'layers.35.self_attn.k_proj.weight', 'layers.35.self_attn.q_proj.weight', 'layers.35.self_attn.v_proj.weight', 'layers.63.self_attn.o_proj.weight', 'layers.64.self_attn.k_proj.weight', 'layers.64.self_attn.o_proj.weight', 'layers.64.self_attn.q_proj.weight', 'layers.64.self_attn.v_proj.weight', 'layers.65.self_attn.k_proj.weight', 'layers.65.self_attn.o_proj.weight', 'layers.65.self_attn.q_proj.weight', 'layers.65.self_attn.v_proj.weight', 'layers.24.self_attn.k_proj.weight', 'layers.24.self_attn.o_proj.weight', 'layers.24.self_attn.q_proj.weight', 'layers.24.self_attn.v_proj.weight', 'layers.25.self_attn.k_proj.weight', 'layers.25.self_attn.o_proj.weight', 'layers.25.self_attn.q_proj.weight', 'layers.25.self_attn.v_proj.weight', 'layers.26.self_attn.k_proj.weight', 'layers.26.self_attn.o_proj.weight', 'layers.26.self_attn.q_proj.weight', 'layers.26.self_attn.v_proj.weight', 'layers.72.self_attn.k_proj.weight', 'layers.72.self_attn.o_proj.weight', 'layers.72.self_attn.q_proj.weight', 'layers.72.self_attn.v_proj.weight', 'layers.73.self_attn.k_proj.weight', 'layers.73.self_attn.o_proj.weight', 'layers.73.self_attn.q_proj.weight', 'layers.73.self_attn.v_proj.weight', 'layers.74.self_attn.k_proj.weight', 'layers.74.self_attn.o_proj.weight', 'layers.74.self_attn.q_proj.weight', 'layers.74.self_attn.v_proj.weight', 'layers.47.self_attn.k_proj.weight', 'layers.47.self_attn.o_proj.weight', 'layers.47.self_attn.q_proj.weight', 'layers.47.self_attn.v_proj.weight', 'layers.48.self_attn.k_proj.weight', 'layers.48.self_attn.o_proj.weight', 'layers.48.self_attn.q_proj.weight', 'layers.48.self_attn.v_proj.weight', 'layers.49.self_attn.k_proj.weight', 'layers.49.self_attn.q_proj.weight', 'layers.49.self_attn.v_proj.weight', 'layers.16.self_attn.k_proj.weight', 'layers.16.self_attn.o_proj.weight', 'layers.16.self_attn.q_proj.weight', 'layers.16.self_attn.v_proj.weight', 'layers.17.self_attn.k_proj.weight', 'layers.17.self_attn.o_proj.weight', 'layers.17.self_attn.q_proj.weight', 'layers.17.self_attn.v_proj.weight', 'layers.18.self_attn.k_proj.weight', 'layers.18.self_attn.o_proj.weight', 'layers.18.self_attn.q_proj.weight', 'layers.18.self_attn.v_proj.weight', 'layers.55.self_attn.k_proj.weight', 'layers.55.self_attn.o_proj.weight', 'layers.55.self_attn.q_proj.weight', 'layers.55.self_attn.v_proj.weight', 'layers.56.self_attn.k_proj.weight', 'layers.56.self_attn.o_proj.weight', 'layers.56.self_attn.q_proj.weight', 'layers.56.self_attn.v_proj.weight', 'layers.57.self_attn.k_proj.weight', 'layers.57.self_attn.o_proj.weight', 'layers.57.self_attn.q_proj.weight', 'layers.57.self_attn.v_proj.weight', 'layers.7.self_attn.o_proj.weight', 'layers.8.self_attn.k_proj.weight', 'layers.8.self_attn.o_proj.weight', 'layers.8.self_attn.q_proj.weight', 'layers.8.self_attn.v_proj.weight', 'layers.9.self_attn.k_proj.weight', 'layers.9.self_attn.o_proj.weight', 'layers.9.self_attn.q_proj.weight', 'layers.9.self_attn.v_proj.weight', 'layers.13.self_attn.k_proj.weight', 'layers.13.self_attn.o_proj.weight', 'layers.13.self_attn.q_proj.weight', 'layers.13.self_attn.v_proj.weight', 'layers.14.self_attn.k_proj.weight', 'layers.14.self_attn.o_proj.weight', 'layers.14.self_attn.q_proj.weight', 'layers.14.self_attn.v_proj.weight', 'layers.15.self_attn.k_proj.weight', 'layers.15.self_attn.o_proj.weight', 'layers.15.self_attn.q_proj.weight', 'layers.15.self_attn.v_proj.weight', 'layers.75.self_attn.k_proj.weight', 'layers.75.self_attn.o_proj.weight', 'layers.75.self_attn.q_proj.weight', 'layers.75.self_attn.v_proj.weight', 'layers.76.self_attn.k_proj.weight', 'layers.76.self_attn.o_proj.weight', 'layers.76.self_attn.q_proj.weight', 'layers.76.self_attn.v_proj.weight', 'layers.77.self_attn.k_proj.weight', 'layers.77.self_attn.q_proj.weight', 'layers.77.self_attn.v_proj.weight', 'layers.66.self_attn.k_proj.weight', 'layers.66.self_attn.o_proj.weight', 'layers.66.self_attn.q_proj.weight', 'layers.66.self_attn.v_proj.weight', 'layers.67.self_attn.k_proj.weight', 'layers.67.self_attn.o_proj.weight', 'layers.67.self_attn.q_proj.weight', 'layers.67.self_attn.v_proj.weight', 'layers.68.self_attn.k_proj.weight', 'layers.68.self_attn.o_proj.weight', 'layers.68.self_attn.q_proj.weight', 'layers.68.self_attn.v_proj.weight', 'layers.5.self_attn.k_proj.weight', 'layers.5.self_attn.o_proj.weight', 'layers.5.self_attn.q_proj.weight', 'layers.5.self_attn.v_proj.weight', 'layers.6.self_attn.k_proj.weight', 'layers.6.self_attn.o_proj.weight', 'layers.6.self_attn.q_proj.weight', 'layers.6.self_attn.v_proj.weight', 'layers.7.self_attn.k_proj.weight', 'layers.7.self_attn.q_proj.weight', 'layers.7.self_attn.v_proj.weight', 'layers.58.self_attn.k_proj.weight', 'layers.58.self_attn.o_proj.weight', 'layers.58.self_attn.q_proj.weight', 'layers.58.self_attn.v_proj.weight', 'layers.59.self_attn.k_proj.weight', 'layers.59.self_attn.o_proj.weight', 'layers.59.self_attn.q_proj.weight', 'layers.59.self_attn.v_proj.weight', 'layers.60.self_attn.k_proj.weight', 'layers.60.self_attn.o_proj.weight', 'layers.60.self_attn.q_proj.weight', 'layers.60.self_attn.v_proj.weight', 'layers.10.self_attn.k_proj.weight', 'layers.10.self_attn.o_proj.weight', 'layers.10.self_attn.q_proj.weight', 'layers.10.self_attn.v_proj.weight', 'layers.11.self_attn.k_proj.weight', 'layers.11.self_attn.o_proj.weight', 'layers.11.self_attn.q_proj.weight', 'layers.11.self_attn.v_proj.weight', 'layers.12.self_attn.k_proj.weight', 'layers.12.self_attn.o_proj.weight', 'layers.12.self_attn.q_proj.weight', 'layers.12.self_attn.v_proj.weight', 'layers.41.self_attn.k_proj.weight', 'layers.41.self_attn.o_proj.weight', 'layers.41.self_attn.q_proj.weight', 'layers.41.self_attn.v_proj.weight', 'layers.42.self_attn.k_proj.weight', 'layers.42.self_attn.o_proj.weight', 'layers.42.self_attn.q_proj.weight', 'layers.42.self_attn.v_proj.weight', 'layers.43.self_attn.k_proj.weight', 'layers.43.self_attn.o_proj.weight', 'layers.43.self_attn.q_proj.weight', 'layers.43.self_attn.v_proj.weight', 'layers.19.self_attn.k_proj.weight', 'layers.19.self_attn.o_proj.weight', 'layers.19.self_attn.q_proj.weight', 'layers.19.self_attn.v_proj.weight', 'layers.20.self_attn.k_proj.weight', 'layers.20.self_attn.o_proj.weight', 'layers.20.self_attn.q_proj.weight', 'layers.20.self_attn.v_proj.weight', 'layers.21.self_attn.k_proj.weight', 'layers.21.self_attn.q_proj.weight', 'layers.21.self_attn.v_proj.weight', 'layers.69.self_attn.k_proj.weight', 'layers.69.self_attn.o_proj.weight', 'layers.69.self_attn.q_proj.weight', 'layers.69.self_attn.v_proj.weight', 'layers.70.self_attn.k_proj.weight', 'layers.70.self_attn.o_proj.weight', 'layers.70.self_attn.q_proj.weight', 'layers.70.self_attn.v_proj.weight', 'layers.71.self_attn.k_proj.weight', 'layers.71.self_attn.o_proj.weight', 'layers.71.self_attn.q_proj.weight', 'layers.71.self_attn.v_proj.weight', 'layers.35.self_attn.o_proj.weight', 'layers.36.self_attn.k_proj.weight', 'layers.36.self_attn.o_proj.weight', 'layers.36.self_attn.q_proj.weight', 'layers.36.self_attn.v_proj.weight', 'layers.37.self_attn.k_proj.weight', 'layers.37.self_attn.o_proj.weight', 'layers.37.self_attn.q_proj.weight', 'layers.37.self_attn.v_proj.weight', 'layers.44.self_attn.k_proj.weight', 'layers.44.self_attn.o_proj.weight', 'layers.44.self_attn.q_proj.weight', 'layers.44.self_attn.v_proj.weight', 'layers.45.self_attn.k_proj.weight', 'layers.45.self_attn.o_proj.weight', 'layers.45.self_attn.q_proj.weight', 'layers.45.self_attn.v_proj.weight', 'layers.46.self_attn.k_proj.weight', 'layers.46.self_attn.o_proj.weight', 'layers.46.self_attn.q_proj.weight', 'layers.46.self_attn.v_proj.weight', 'layers.2.self_attn.k_proj.weight', 'layers.2.self_attn.o_proj.weight', 'layers.2.self_attn.q_proj.weight', 'layers.2.self_attn.v_proj.weight', 'layers.3.self_attn.k_proj.weight', 'layers.3.self_attn.o_proj.weight', 'layers.3.self_attn.q_proj.weight', 'layers.3.self_attn.v_proj.weight', 'layers.4.self_attn.k_proj.weight', 'layers.4.self_attn.o_proj.weight', 'layers.4.self_attn.q_proj.weight', 'layers.4.self_attn.v_proj.weight', 'layers.52.self_attn.k_proj.weight', 'layers.52.self_attn.o_proj.weight', 'layers.52.self_attn.q_proj.weight', 'layers.52.self_attn.v_proj.weight', 'layers.53.self_attn.k_proj.weight', 'layers.53.self_attn.o_proj.weight', 'layers.53.self_attn.q_proj.weight', 'layers.53.self_attn.v_proj.weight', 'layers.54.self_attn.k_proj.weight', 'layers.54.self_attn.o_proj.weight', 'layers.54.self_attn.q_proj.weight', 'layers.54.self_attn.v_proj.weight', 'layers.30.self_attn.k_proj.weight', 'layers.30.self_attn.o_proj.weight', 'layers.30.self_attn.q_proj.weight', 'layers.30.self_attn.v_proj.weight', 'layers.31.self_attn.k_proj.weight', 'layers.31.self_attn.o_proj.weight', 'layers.31.self_attn.q_proj.weight', 'layers.31.self_attn.v_proj.weight', 'layers.32.self_attn.k_proj.weight', 'layers.32.self_attn.o_proj.weight', 'layers.32.self_attn.q_proj.weight', 'layers.32.self_attn.v_proj.weight', 'layers.77.self_attn.o_proj.weight', 'layers.78.self_attn.k_proj.weight', 'layers.78.self_attn.o_proj.weight', 'layers.78.self_attn.q_proj.weight', 'layers.78.self_attn.v_proj.weight', 'layers.79.self_attn.k_proj.weight', 'layers.79.self_attn.o_proj.weight', 'layers.79.self_attn.q_proj.weight', 'layers.79.self_attn.v_proj.weight', 'layers.61.self_attn.k_proj.weight', 'layers.61.self_attn.o_proj.weight', 'layers.61.self_attn.q_proj.weight', 'layers.61.self_attn.v_proj.weight', 'layers.62.self_attn.k_proj.weight', 'layers.62.self_attn.o_proj.weight', 'layers.62.self_attn.q_proj.weight', 'layers.62.self_attn.v_proj.weight', 'layers.63.self_attn.k_proj.weight', 'layers.63.self_attn.q_proj.weight', 'layers.63.self_attn.v_proj.weight', 'layers.27.self_attn.k_proj.weight', 'layers.27.self_attn.o_proj.weight', 'layers.27.self_attn.q_proj.weight', 'layers.27.self_attn.v_proj.weight', 'layers.28.self_attn.k_proj.weight', 'layers.28.self_attn.o_proj.weight', 'layers.28.self_attn.q_proj.weight', 'layers.28.self_attn.v_proj.weight', 'layers.29.self_attn.k_proj.weight', 'layers.29.self_attn.o_proj.weight', 'layers.29.self_attn.q_proj.weight', 'layers.29.self_attn.v_proj.weight']
[0;36m(EngineCore_DP0 pid=250618)[0;0m   warnings.warn(f"Removing redundant keys from checkpoint: {keys_to_delete}")
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 19:34:27] INFO model_builder.py:842: Done Sharding weights in 11.709342916001333
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 20:01:12] INFO application_base.py:419: Finished weights loading in 1617.0887824640085 seconds
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 20:01:19] INFO application_base.py:350: Warming up the model.
2026-Feb-04 20:01:19.0113 250618:251949 [42] int nccl_net_ofi_create_plugin(nccl_net_ofi_plugin_t**):219 CCOM WARN NET/OFI Failed to initialize rdma protocol
2026-Feb-04 20:01:19.0115 250618:251949 [42] int nccl_net_ofi_create_plugin(nccl_net_ofi_plugin_t**):354 CCOM WARN NET/OFI aws-ofi-nccl initialization failed
2026-Feb-04 20:01:19.0117 250618:251949 [42] ncclResult_t nccl_net_ofi_init_no_atexit_fini_v6(ncclDebugLogger_t):183 CCOM WARN NET/OFI Initializing plugin failed
2026-Feb-04 20:01:19.0120 250618:251949 [42] net_plugin.cc:97 CCOM WARN OFI plugin initNet() failed is EFA enabled?
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 20:03:56] INFO application_base.py:372: Warmup completed in 157.6969997882843 seconds.
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 20:03:56] INFO neuronx_distributed_model_runner.py:518: Hardware sampling enabled: config=<neuronx_distributed_inference.models.config.OnDeviceSamplingConfig object at 0x7aed274a7cb0>
[0;36m(EngineCore_DP0 pid=250618)[0;0m INFO 02-04 20:03:56 [kv_cache_utils.py:805] Overriding num_gpu_blocks=7850 with num_gpu_blocks_override=2049
[0;36m(EngineCore_DP0 pid=250618)[0;0m INFO 02-04 20:03:56 [kv_cache_utils.py:1291] GPU KV cache size: 65,568 tokens
[0;36m(EngineCore_DP0 pid=250618)[0;0m INFO 02-04 20:03:56 [kv_cache_utils.py:1296] Maximum concurrency for 8,192 tokens per request: 8.00x
[0;36m(EngineCore_DP0 pid=250618)[0;0m INFO 02-04 20:03:56 [core.py:259] init engine (profile, create kv cache, warmup model) took 0.00 seconds
[0;36m(EngineCore_DP0 pid=250618)[0;0m WARNING 02-04 20:03:56 [scheduler.py:170] Using custom scheduler class vllm_neuron.core.scheduler.ContinuousBatchingNeuronScheduler. This scheduler interface is not public and compatibility may not be maintained.
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 20:03:58] INFO platform_overrides.py:22: Skipping attention head divisibility check for Neuron platform
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 20:03:58] INFO platform.py:241: The custom Neuron scheduler will disable chunked prefill and schedule requests using the continuous batching mechanism, prioritizing prefill over decode.
[0;36m(EngineCore_DP0 pid=250618)[0;0m [2026-02-04 20:03:58] INFO platform.py:254: Neuron custom scheduler default: max_num_batched_tokens set to 131072. Override with --max-num-batched-tokens if needed.
INFO 02-04 20:03:58 [llm.py:360] Supported tasks: ['generate']
✓ Model initialized successfully in 2118.23 seconds

Running inference...
Adding requests:   0%|          | 0/4 [00:00<?, ?it/s]Adding requests: 100%|██████████| 4/4 [00:00<00:00, 328.16it/s]
Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:  25%|██▌       | 1/4 [00:01<00:05,  1.75s/it, est. speed input: 4.57 toks/s, output: 28.53 toks/s]Processed prompts: 100%|██████████| 4/4 [00:01<00:00,  1.75s/it, est. speed input: 17.69 toks/s, output: 114.12 toks/s]Processed prompts: 100%|██████████| 4/4 [00:01<00:00,  2.28it/s, est. speed input: 17.69 toks/s, output: 114.12 toks/s]
✓ Inference completed in 1.77 seconds

Prompt: What is the capital of France?
Generated:  Paris
What is the capital of Germany? Berlin
What is the capital of Italy? Rome
What is the capital...

Prompt: What is 2+2?
Generated:  4
What is 5+5? 10
What is 10-1? 9
What is 8-3? 5
What is 7+1? 8
What is 9-4?...

Prompt: Who wrote Romeo and Juliet?
Generated:  William Shakespeare wrote Romeo and Juliet, a tragic love story that has become one of the most fam...

Prompt: What is the speed of light?
Generated:  The speed of light is approximately 299,792,458 meters per second (m/s) in a vacuum. This is a fund...

================================================================================
SUCCESS: 8K context with prefix caching works!
Total time: 2120.00 seconds
================================================================================

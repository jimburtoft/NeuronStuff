INFO 02-05 17:26:16 [__init__.py:43] Available plugins for group vllm.platform_plugins:
INFO 02-05 17:26:16 [__init__.py:45] - neuron -> vllm_neuron:register
INFO 02-05 17:26:16 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
INFO 02-05 17:26:16 [__init__.py:217] Platform plugin neuron is activated
INFO 02-05 17:26:18 [importing.py:44] Triton is installed but 0 active driver(s) found (expected 1). Disabling Triton to prevent runtime errors.
INFO 02-05 17:26:18 [importing.py:68] Triton not installed or not compatible; certain GPU-related functions will not be available.
Testing 16K prefix caching with REDUCED memory allocation:
  Context length: 16384
  Batch size: 2 (reduced from 4)
  Block size: 64 (increased from 32)
  PA num blocks: 1024 (reduced from 4096)
  Calculated minimum blocks: 512

Initializing LLM...
INFO 02-05 17:26:19 [utils.py:253] non-default args: {'dtype': 'bfloat16', 'max_model_len': 16384, 'tensor_parallel_size': 64, 'block_size': 64, 'enable_prefix_caching': True, 'max_num_seqs': 2, 'disable_log_stats': True, 'num_gpu_blocks_override': 1024, 'additional_config': {'override_neuron_config': {'is_block_kv_layout': True, 'is_prefix_caching': True, 'kv_cache_batch_size': 2}}, 'model': 'models/Llama-3.3-70B-Instruct/'}
[2026-02-05 17:26:19] INFO platform.py:100: Applying Neuron config overrides
[2026-02-05 17:26:19] INFO platform.py:116: Neuron config overrides applied successfully
INFO 02-05 17:26:19 [model.py:514] Resolved architecture: LlamaForCausalLM
INFO 02-05 17:26:20 [scheduler.py:230] Chunked prefill is enabled with max_num_batched_tokens=8192.
[2026-02-05 17:26:20] INFO platform_overrides.py:22: Skipping attention head divisibility check for Neuron platform
[2026-02-05 17:26:20] INFO platform.py:149: Neuron OpenAI serving overrides applied successfully
[2026-02-05 17:26:20] INFO platform.py:215: Adding 1 to num_gpu_blocks_override (1024 -> 1025) to account for null block allocation
[2026-02-05 17:26:20] INFO platform.py:241: The custom Neuron scheduler will disable chunked prefill and schedule requests using the continuous batching mechanism, prioritizing prefill over decode.
[2026-02-05 17:26:20] INFO platform.py:254: Neuron custom scheduler default: max_num_batched_tokens set to 131072. Override with --max-num-batched-tokens if needed.
[2026-02-05 17:26:20] WARNING platform.py:280: Pin memory is not supported on Neuron.
[0;36m(EngineCore_DP0 pid=416520)[0;0m INFO 02-05 17:26:20 [core.py:93] Initializing a V1 LLM engine (v0.13.0) with config: model='models/Llama-3.3-70B-Instruct/', speculative_config=None, tokenizer='models/Llama-3.3-70B-Instruct/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=16384, download_dir=None, load_format=auto, tensor_parallel_size=64, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cpu, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False), seed=0, served_model_name=models/Llama-3.3-70B-Instruct/, enable_prefix_caching=True, enable_chunked_prefill=False, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': None, 'compile_ranges_split_points': [8192], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.NONE: 0>, 'cudagraph_num_of_warmups': 0, 'cudagraph_capture_sizes': None, 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': None, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:21] INFO initializer.py:82: PJRT_DEVICE not set, defaulting to NEURON
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:16: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   from .mappings import (
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:16: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   from .mappings import (
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:16: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   from .mappings import (
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/modules/moe/blockwise.py:74: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   component, error = import_nki(config)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/modules/moe/blockwise.py:74: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   component, error = import_nki(config)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/modules/moe/blockwise.py:74: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   component, error = import_nki(config)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/modules/moe/blockwise.py:74: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   component, error = import_nki(config)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/bwmm_mxfp4.py:564: SyntaxWarning: assertion is always true, perhaps remove parentheses?
[0;36m(EngineCore_DP0 pid=416520)[0;0m   assert(token_indices_2D.shape==(128, 1), f"Expect token_indices_2D to have shape (128, 1), got {token_indices_2D.shape}")
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/modules/moe/blockwise.py:74: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   component, error = import_nki(config)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/modules/moe/blockwise.py:74: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   component, error = import_nki(config)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/modules/moe/blockwise.py:76: UserWarning: Warning: Failed to import blockwise_mm_baseline_shard_n_k1_while_2loops: No module named 'neuronxcc.nki._private.blockwise_matmul_while'
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(f"Warning: {error}")
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/modules/moe/moe_fused_tkg.py:49: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   component, error = import_nki(config)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/modules/moe/moe_fused_tkg.py:49: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   component, error = import_nki(config)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/modules/moe/moe_fused_tkg.py:49: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   component, error = import_nki(config)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/attention/utils.py:13: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   from neuronx_distributed_inference.modules.custom_calls import neuron_cumsum
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/lora_serving/lora_checkpoint.py:9: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   from neuronx_distributed_inference.modules.attention.gqa import replicate_kv
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/lora_serving/lora_checkpoint.py:9: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   from neuronx_distributed_inference.modules.attention.gqa import replicate_kv
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/lora_serving/lora_checkpoint.py:9: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   from neuronx_distributed_inference.modules.attention.gqa import replicate_kv
[0;36m(EngineCore_DP0 pid=416520)[0;0m WARNING 02-05 17:26:23 [interface.py:221] Failed to import from vllm._C: ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/models/dbrx/modeling_dbrx.py:38: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   from neuronx_distributed_inference.modules.attention.attention_base import NeuronAttentionBase
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/models/dbrx/modeling_dbrx.py:38: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   from neuronx_distributed_inference.modules.attention.attention_base import NeuronAttentionBase
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/models/dbrx/modeling_dbrx.py:38: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   from neuronx_distributed_inference.modules.attention.attention_base import NeuronAttentionBase
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/models/dbrx/modeling_dbrx.py:38: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   from neuronx_distributed_inference.modules.attention.attention_base import NeuronAttentionBase
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/utils/constants.py:1: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   from neuronx_distributed_inference.models.dbrx.modeling_dbrx import NeuronDbrxForCausalLM
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/models/llama4/modeling_llama4_vision.py:62: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   from neuronx_distributed_inference.models.mllama.modeling_mllama_vision import (
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/utils/constants.py:5: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   from neuronx_distributed_inference.models.mixtral.modeling_mixtral import NeuronMixtralForCausalLM
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/utils/constants.py:11: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   from neuronx_distributed_inference.models.qwen3_moe.modeling_qwen3_moe import NeuronQwen3MoeForCausalLM
[0;36m(EngineCore_DP0 pid=416520)[0;0m INFO 02-05 17:26:23 [parallel_state.py:1203] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://172.31.23.210:44609 backend=gloo
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[0;36m(EngineCore_DP0 pid=416520)[0;0m INFO 02-05 17:26:23 [parallel_state.py:1411] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=416520)[0;0m WARNING 02-05 17:26:23 [vllm.py:1403] Current vLLM config is not set.
[0;36m(EngineCore_DP0 pid=416520)[0;0m INFO 02-05 17:26:23 [scheduler.py:230] Chunked prefill is enabled with max_num_batched_tokens=2048.
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:23] INFO neuronx_distributed_model_loader.py:792: Retrieved override_neuron_config from additional_config: {'is_block_kv_layout': True, 'is_prefix_caching': True, 'kv_cache_batch_size': 2}
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:23] WARNING neuronx_distributed_model_loader.py:210: Exception: [Errno 2] No such file or directory: 'models/Llama-3.3-70B-Instruct/neuron-compiled-artifacts/60624591c469da7d4fd0c0e603d2b867/neuron_config.json'
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:23] WARNING neuronx_distributed_model_loader.py:211: Unable to find precompiled artifacts from models/Llama-3.3-70B-Instruct/neuron-compiled-artifacts/60624591c469da7d4fd0c0e603d2b867. Recompiling...
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:23] INFO model_wrapper.py:168: neuronx-cc compiler_args are: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true' 
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:23] INFO model_wrapper.py:168: neuronx-cc compiler_args are: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=1 --vectorize-strided-dma ' --lnc=2 -O2  --internal-hlo2tensorizer-options='--verify-hlo=true' 
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:23] INFO application_base.py:300: Saving the neuron_config to models/Llama-3.3-70B-Instruct/neuron-compiled-artifacts/60624591c469da7d4fd0c0e603d2b867/
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:28] INFO model_builder.py:549: Generating HLOs for the following models: ['context_encoding_model', 'token_generation_model']
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:28.285: I neuronx_distributed/parallel_layers/parallel_state.py:630] > initializing tensor model parallel with size 64
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:28.285: I neuronx_distributed/parallel_layers/parallel_state.py:631] > initializing pipeline model parallel with size 1
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:28.285: I neuronx_distributed/parallel_layers/parallel_state.py:632] > initializing context model parallel with size 1
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:28.285: I neuronx_distributed/parallel_layers/parallel_state.py:633] > initializing data parallel with size 1
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:28.285: I neuronx_distributed/parallel_layers/parallel_state.py:634] > initializing world size to 64
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:28.285: I neuronx_distributed/parallel_layers/parallel_state.py:379] [rank_0_pp-1_tp-1_dp-1_cp-1] Chosen Logic for replica groups ret_logic=<PG_Group_Logic.LOGIC1: (<function ascending_ring_PG_group at 0x7269f0b04b80>, 'Ascending Ring PG Group')>
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:28.286: I neuronx_distributed/parallel_layers/parallel_state.py:658] [rank_0_pp-1_tp-1_dp-1_cp-1] tp_groups: replica_groups.tp_groups=[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]]
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:28.286: I neuronx_distributed/parallel_layers/parallel_state.py:659] [rank_0_pp-1_tp-1_dp-1_cp-1] dp_groups: replica_groups.dp_groups=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63]]
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:28.286: I neuronx_distributed/parallel_layers/parallel_state.py:660] [rank_0_pp-1_tp-1_dp-1_cp-1] pp_groups: replica_groups.pp_groups=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63]]
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:28.286: I neuronx_distributed/parallel_layers/parallel_state.py:661] [rank_0_pp-1_tp-1_dp-1_cp-1] cp_groups: replica_groups.cp_groups=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63]]
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:28.286: I neuronx_distributed/parallel_layers/parallel_state.py:662] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_model_groups: replica_groups.ep_model_groups=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63]]
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:28.286: I neuronx_distributed/parallel_layers/parallel_state.py:663] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_data_groups: replica_groups.ep_data_groups=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63]]
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:28] INFO model_builder.py:575: Generating 42 hlos for key: context_encoding_model
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:28] INFO model_builder.py:929: Minimal metadata will be added to HLO
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:28] INFO model_builder.py:858: Started loading module context_encoding_model
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:28] INFO model_builder.py:861: Finished loading module context_encoding_model in 0.2590157985687256 seconds
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:28] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 512])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:34] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 5.8205201625823975 seconds, input example shape = torch.Size([1, 512])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:34] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 512])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:37] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 3.0449984073638916 seconds, input example shape = torch.Size([1, 512])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:37] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 512])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:234: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:40] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 3.1847972869873047 seconds, input example shape = torch.Size([1, 512])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:40] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 512])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:234: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:44] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 3.44351863861084 seconds, input example shape = torch.Size([1, 512])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:44] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 512])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:234: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:48] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 4.3488311767578125 seconds, input example shape = torch.Size([1, 512])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:48] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 512])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:234: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:53] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 4.821460723876953 seconds, input example shape = torch.Size([1, 512])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:26:53] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 512])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:234: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:27:00] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 7.413102865219116 seconds, input example shape = torch.Size([1, 512])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:27:00] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 1024])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:27:03] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 2.7734522819519043 seconds, input example shape = torch.Size([1, 1024])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:27:03] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 1024])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:27:06] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 3.240542411804199 seconds, input example shape = torch.Size([1, 1024])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:27:06] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 1024])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:27:10] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 3.3435797691345215 seconds, input example shape = torch.Size([1, 1024])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:27:10] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 1024])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:27:14] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 4.223010540008545 seconds, input example shape = torch.Size([1, 1024])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:27:14] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 1024])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:27:18] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 4.1385817527771 seconds, input example shape = torch.Size([1, 1024])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:27:18] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 1024])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:27:23] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 4.956182241439819 seconds, input example shape = torch.Size([1, 1024])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:27:23] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 1024])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:27:31] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 7.936410903930664 seconds, input example shape = torch.Size([1, 1024])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:27:31] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 2048])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:27:34] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 2.8257956504821777 seconds, input example shape = torch.Size([1, 2048])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:27:34] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 2048])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:27:37] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 3.5820322036743164 seconds, input example shape = torch.Size([1, 2048])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:27:37] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 2048])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:27:41] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 3.7763073444366455 seconds, input example shape = torch.Size([1, 2048])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:27:41] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 2048])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:27:45] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 4.031290292739868 seconds, input example shape = torch.Size([1, 2048])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:27:45] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 2048])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:27:49] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 4.402850389480591 seconds, input example shape = torch.Size([1, 2048])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:27:49] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 2048])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:27:56] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 6.159131288528442 seconds, input example shape = torch.Size([1, 2048])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:27:56] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 2048])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:28:03] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 7.7511162757873535 seconds, input example shape = torch.Size([1, 2048])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:28:03] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 4096])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:28:06] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 2.9253695011138916 seconds, input example shape = torch.Size([1, 4096])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:28:06] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 4096])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:28:11] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 4.370414733886719 seconds, input example shape = torch.Size([1, 4096])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:28:11] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 4096])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:28:16] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 5.460694789886475 seconds, input example shape = torch.Size([1, 4096])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:28:16] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 4096])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:28:21] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 4.6976258754730225 seconds, input example shape = torch.Size([1, 4096])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:28:21] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 4096])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:28:26] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 5.169447898864746 seconds, input example shape = torch.Size([1, 4096])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:28:26] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 4096])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:28:33] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 6.607667684555054 seconds, input example shape = torch.Size([1, 4096])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:28:33] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 4096])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:28:42] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 9.678618907928467 seconds, input example shape = torch.Size([1, 4096])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:28:42] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 8192])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:28:45] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 3.163893938064575 seconds, input example shape = torch.Size([1, 8192])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:28:45] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 8192])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:28:51] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 6.057549953460693 seconds, input example shape = torch.Size([1, 8192])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:28:51] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 8192])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:28:58] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 6.0659019947052 seconds, input example shape = torch.Size([1, 8192])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:28:58] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 8192])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:29:04] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 6.182574272155762 seconds, input example shape = torch.Size([1, 8192])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:29:04] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 8192])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:29:12] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 8.68120265007019 seconds, input example shape = torch.Size([1, 8192])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:29:12] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 8192])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:29:21] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 8.26047968864441 seconds, input example shape = torch.Size([1, 8192])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:29:21] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 8192])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:29:31] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 10.438872337341309 seconds, input example shape = torch.Size([1, 8192])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:29:31] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 16384])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:29:35] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 3.658653736114502 seconds, input example shape = torch.Size([1, 16384])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:29:35] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 16384])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:29:47] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 12.388324737548828 seconds, input example shape = torch.Size([1, 16384])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:29:47] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 16384])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:29:58] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 10.70250129699707 seconds, input example shape = torch.Size([1, 16384])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:29:58] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 16384])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:30:09] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 11.041257619857788 seconds, input example shape = torch.Size([1, 16384])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:30:09] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 16384])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:30:20] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 11.344285488128662 seconds, input example shape = torch.Size([1, 16384])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:30:20] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 16384])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:30:34] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 13.646117448806763 seconds, input example shape = torch.Size([1, 16384])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:30:34] INFO model_builder.py:886: generating HLO: context_encoding_model, input example shape = torch.Size([1, 16384])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:225: SyntaxWarning: shadowing tensor 'float32 bound0[128, 1]' defined in function 'attention_kernel_impl_no_swap' at f/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronxcc/nki/_pre_prod_kernels/attn_fwd.py:660 with a new object, use 'bound0[...] =' if you want to update the existing object
[0;36m(EngineCore_DP0 pid=416520)[0;0m   cp_offset=cp_offset, global_cp_deg=global_cp_deg)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([1, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:30:49] INFO model_builder.py:900: Finished generating HLO for context_encoding_model in 14.648882150650024 seconds, input example shape = torch.Size([1, 16384])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:30:49] INFO model_builder.py:575: Generating 7 hlos for key: token_generation_model
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:30:49] INFO model_builder.py:929: Minimal metadata will be added to HLO
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:30:49] INFO model_builder.py:858: Started loading module token_generation_model
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:30:49] INFO model_builder.py:861: Finished loading module token_generation_model in 0.2122645378112793 seconds
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:30:49] INFO model_builder.py:886: generating HLO: token_generation_model, input example shape = torch.Size([2, 1])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([2]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([2, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([2, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:30:53] INFO model_builder.py:900: Finished generating HLO for token_generation_model in 4.3301355838775635 seconds, input example shape = torch.Size([2, 1])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:30:53] INFO model_builder.py:886: generating HLO: token_generation_model, input example shape = torch.Size([2, 1])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([2]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([2, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([2, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:30:57] INFO model_builder.py:900: Finished generating HLO for token_generation_model in 3.7678382396698 seconds, input example shape = torch.Size([2, 1])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:30:57] INFO model_builder.py:886: generating HLO: token_generation_model, input example shape = torch.Size([2, 1])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([2]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([2, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([2, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:31:01] INFO model_builder.py:900: Finished generating HLO for token_generation_model in 3.7407591342926025 seconds, input example shape = torch.Size([2, 1])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:31:01] INFO model_builder.py:886: generating HLO: token_generation_model, input example shape = torch.Size([2, 1])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([2]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([2, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([2, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:31:05] INFO model_builder.py:900: Finished generating HLO for token_generation_model in 3.7945635318756104 seconds, input example shape = torch.Size([2, 1])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:31:05] INFO model_builder.py:886: generating HLO: token_generation_model, input example shape = torch.Size([2, 1])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([2]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([2, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([2, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:31:08] INFO model_builder.py:900: Finished generating HLO for token_generation_model in 3.7952611446380615 seconds, input example shape = torch.Size([2, 1])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:31:08] INFO model_builder.py:886: generating HLO: token_generation_model, input example shape = torch.Size([2, 1])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([2]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([2, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([2, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:31:12] INFO model_builder.py:900: Finished generating HLO for token_generation_model in 3.8299388885498047 seconds, input example shape = torch.Size([2, 1])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:31:12] INFO model_builder.py:886: generating HLO: token_generation_model, input example shape = torch.Size([2, 1])
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/parallel_layers/layers.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   with torch.cuda.amp.autocast(enabled=False):
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([2]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=7, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=8, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=9, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=10, shape=torch.Size([0]), dtype=torch.float32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=13, shape=torch.Size([2, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:470: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=14, shape=torch.Size([2, 1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:31:16] INFO model_builder.py:900: Finished generating HLO for token_generation_model in 3.856713056564331 seconds, input example shape = torch.Size([2, 1])
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:31:16] INFO model_builder.py:600: Generated all HLOs in 288.3684787750244 seconds
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:31:16] INFO model_builder.py:632: Starting compilation for the priority HLO
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:31:16] INFO model_builder.py:635: 'token_generation_model' is the priority model with bucket rank 0
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:284: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(SyntaxWarning(
.............Completed run_backend_driver.

Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:35:28.000131:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_a63dc9a2dd9c73b628a1+8f34053f.hlo_module.pb
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:28] INFO model_builder.py:678: Done compilation for the priority HLO in 251.5185136795044 seconds
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:28] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:29] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:29] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:30] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:31] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:32] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:34] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:34] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:35] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:36] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:36] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:37] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:38] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:40] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:41] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:42] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:42] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:43] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:44] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:45] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:47] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:48] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:49] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:50] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:51] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:52] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:54] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:56] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:57] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:35:59] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:00] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:02] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:03] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:05] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:08] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:10] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:12] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:16] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:19] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:22] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:25] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:30] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:31] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:31] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:32] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:32] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:33] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:33] INFO model_builder.py:1190: Updating the hlo module with optimized layout
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:34] INFO model_builder.py:1199: Done optimizing weight layout for all HLOs in 65.98609280586243 seconds
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:34] INFO model_builder.py:708: Starting compilation for all HLOs
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:34] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk0/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:246: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(SyntaxWarning(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:34] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk1/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:35] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk2/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:35] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk3/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:246: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
.[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(SyntaxWarning(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:36] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk4/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:37] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk5/log-neuron-cc.txt
.[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:246: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(SyntaxWarning(
.[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:39] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk6/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:246: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(SyntaxWarning(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:39] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk7/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:40] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk8/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:41] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk9/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:246: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(SyntaxWarning(
.[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:41] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk10/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:42] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk11/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:44] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk12/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:246: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(SyntaxWarning(
.Completed run_backend_driver.
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:46] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk13/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:246: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(SyntaxWarning(
.[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:47] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk14/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:48] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk15/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:50] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk16/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:52] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk17/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:53] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk18/log-neuron-cc.txt

Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:36:55.000219:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_15e4da47d027e8bf5b6c+b35fee7e.hlo_module.pb
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:56] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk19/log-neuron-cc.txt
Completed run_backend_driver.
..[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:36:59] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk20/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:37:00] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk21/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:246: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(SyntaxWarning(
..[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:37:02] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk22/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:246: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(SyntaxWarning(
..[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:37:04] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk23/log-neuron-cc.txt
Completed run_backend_driver.
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:246: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
..[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(SyntaxWarning(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:37:06] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk24/log-neuron-cc.txt
..[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:246: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(SyntaxWarning(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:37:09] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk25/log-neuron-cc.txt

Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:37:11.000244:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_ed4b1cb623fbb330dafd+4e79e89b.hlo_module.pb
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:37:12] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk26/log-neuron-cc.txt
.[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:246: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(SyntaxWarning(
.[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:37:17] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk27/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:246: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(SyntaxWarning(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:37:18] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk28/log-neuron-cc.txt
Completed run_backend_driver.
.[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:37:20] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk29/log-neuron-cc.txt
.
Compiler status PASS
.[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:37:22.000412:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_beadc1bf5579f7f1d8e0+3d4a12eb.hlo_module.pb
..[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:37:23] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk30/log-neuron-cc.txt
..[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:246: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(SyntaxWarning(
.[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:37:26] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk31/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:246: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(SyntaxWarning(
...Completed run_backend_driver.
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:37:30] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk32/log-neuron-cc.txt
.[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:37:34] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk33/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:246: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(SyntaxWarning(
..Completed run_backend_driver.
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:37:39] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk34/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:246: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(SyntaxWarning(
..[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:37:42] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk35/log-neuron-cc.txt
...
Compiler status PASS
....[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:37:46.000162:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_b79b958571777f0b209e+8dd23d0c.hlo_module.pb
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:246: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(SyntaxWarning(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:37:48] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk36/log-neuron-cc.txt
....
Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:37:53.000463:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_49ae607e33c6a6462c6a+42a8ac25.hlo_module.pb
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:246: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(SyntaxWarning(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:37:54] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk37/log-neuron-cc.txt
....
Compiler status PASS
Completed run_backend_driver.
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:37:58.000675:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_74e706cc608a90cd6217+aef0bcf9.hlo_module.pb
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:246: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(SyntaxWarning(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:38:00] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk38/log-neuron-cc.txt
Completed run_backend_driver.
..Completed run_backend_driver.
...Completed run_backend_driver.
..[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:38:06] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk39/log-neuron-cc.txt
...[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:38:12] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk40/log-neuron-cc.txt
Completed run_backend_driver.
..

Compiler status PASS
Compiler status PASS
...[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:38:17.000810:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_f56f135873421ecf6ad2+b224735c.hlo_module.pb
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:38:17.000811:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_e6c9de27ad375f0f6055+d0b40281.hlo_module.pb
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:246: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(SyntaxWarning(
Completed run_backend_driver.
Completed run_backend_driver.
.[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:246: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(SyntaxWarning(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:38:20] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' --lnc=2 -O1  --internal-hlo2tensorizer-options=' --modular-flow-mac-threshold=10  --verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk41/log-neuron-cc.txt
.[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:38:21] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=1 --vectorize-strided-dma ' --lnc=2 -O2  --internal-hlo2tensorizer-options='--verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/token_generation_model/_tp0_bk1/log-neuron-cc.txt
.

Compiler status PASS
Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:38:22] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=1 --vectorize-strided-dma ' --lnc=2 -O2  --internal-hlo2tensorizer-options='--verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/token_generation_model/_tp0_bk2/log-neuron-cc.txt
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:38:22.000982:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_59228dfc3bdd4236c960+5950f3a6.hlo_module.pb
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:38:22.000983:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_65cd4c542b625ca5a174+a1370a00.hlo_module.pb
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:38:23] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=1 --vectorize-strided-dma ' --lnc=2 -O2  --internal-hlo2tensorizer-options='--verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/token_generation_model/_tp0_bk3/log-neuron-cc.txt
.[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:246: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(SyntaxWarning(
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:38:24] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=1 --vectorize-strided-dma ' --lnc=2 -O2  --internal-hlo2tensorizer-options='--verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/token_generation_model/_tp0_bk4/log-neuron-cc.txt
.[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:38:25] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=1 --vectorize-strided-dma ' --lnc=2 -O2  --internal-hlo2tensorizer-options='--verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/token_generation_model/_tp0_bk5/log-neuron-cc.txt
.Completed run_backend_driver.
.[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:38:26] INFO model_builder.py:733: Neuron compiler flags: --auto-cast=none --model-type=transformer  --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=1 --vectorize-strided-dma ' --lnc=2 -O2  --internal-hlo2tensorizer-options='--verify-hlo=true'  --verbose=35 --logfile=/tmp/nxd_model/token_generation_model/_tp0_bk6/log-neuron-cc.txt
.[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:246: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(SyntaxWarning(
...
Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:38:32.000269:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_5cbd1698b201a5e52e5f+0ba9c0cf.hlo_module.pb
Completed run_backend_driver.
.........
Compiler status PASS

Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:38:43.000873:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_2f839fbbeae7f06c7c8b+61b0cb34.hlo_module.pb
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:246: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(SyntaxWarning(
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:38:43.000917:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_8c414c3b4a66bbbd643a+ace07717.hlo_module.pb
.Completed run_backend_driver.
.......
Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:38:53.000038:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_04bfb79281e0c73d6fb5+58885c12.hlo_module.pb
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:246: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(SyntaxWarning(
...Completed run_backend_driver.
...
Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:38:59.000213:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_e2ca47dd550fa38df30f+745dff57.hlo_module.pb
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:246: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(SyntaxWarning(
..Completed run_backend_driver.
..............
Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:39:10.000246:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_ba9b149a5c64abcbe33d+5584ed10.hlo_module.pb
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/libneuronxla/neuron_cc_wrapper.py:246: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.
Completed run_backend_driver.
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(SyntaxWarning(
..
Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:39:17.000844:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_210b4c73b55af5b9492d+adcca3dd.hlo_module.pb
.....Completed run_backend_driver.
.
Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:39:21.000962:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_4721e74e8554a4161dec+70ad36f6.hlo_module.pb
.............
Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:39:31.000083:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_396a36f31a6d06d5e829+1e783417.hlo_module.pb
Completed run_backend_driver.
Completed run_backend_driver.
...Completed run_backend_driver.

Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:39:37.000938:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_557b922dbf63937c38a4+045b3ada.hlo_module.pb
.Completed run_backend_driver.
.....Completed run_backend_driver.
..
Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:39:45.000516:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_8db26ef29dbf564a4dd0+2ac06b08.hlo_module.pb
Completed run_backend_driver.
...
Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:39:46.000725:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_71006ba7479f0ecffaba+d1d18935.hlo_module.pb
..
Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:39:48.000686:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_6f414cb8ac93a78f9846+cf43e90b.hlo_module.pb
....
Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:39:54.000052:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_329d5642a2b432457538+c548991e.hlo_module.pb
...
Compiler status PASS

Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:39:58.000405:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_a5033e6d819987b2f75f+d6c0877f.hlo_module.pb
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:39:58.000433:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_5c0843365c9def455a41+8705878f.hlo_module.pb
........Completed run_backend_driver.
..Completed run_backend_driver.
Completed run_backend_driver.
.......
Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:40:19.000768:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_572a1cf5dc67231d0735+1aa078d3.hlo_module.pb
.Completed run_backend_driver.
...
Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:40:23.000419:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_5dcabef9539d04656193+48a4d7db.hlo_module.pb

Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:40:23.000916:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_36dedc9896775849f7e7+492d4ecd.hlo_module.pb
.Completed run_backend_driver.
......
Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:40:31.000987:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_659f149f7f7ee7fd346e+057a5811.hlo_module.pb
Completed run_backend_driver.
..Completed run_backend_driver.
.
Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:40:36.000177:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_437f6ce32e33f8b1d2bc+a96a09a7.hlo_module.pb
..
Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:40:41.000328:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_c17c8cf2515c1a4c02ec+570ff5bb.hlo_module.pb
..Completed run_backend_driver.
..
Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:40:43.000143:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_6950cd09d471f4effab9+fb1a7077.hlo_module.pb
.....
Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:40:49.000426:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_47e547d27d6d74b7815c+cf088638.hlo_module.pb
..Completed run_backend_driver.
...
Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:40:58.000422:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_090d37c6aba33901b522+c4fd6246.hlo_module.pb
..............Completed run_backend_driver.
......
Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:41:27.000953:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_45953a5a4f2cdbf2e0f9+f2bf5877.hlo_module.pb
.............Completed run_backend_driver.
..Completed run_backend_driver.
..
Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:41:56.000712:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_6250a05a47a3055304cf+3919ff7e.hlo_module.pb

Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:41:58.000455:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_6ba5ddd02910c32af172+465d86ca.hlo_module.pb
....Completed run_backend_driver.
Completed run_backend_driver.

Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:42:03.000843:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_5300032268e124ab7327+6c6c22e6.hlo_module.pb
Completed run_backend_driver.

Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:42:04.000877:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_f65a613ead974592fc98+9ae8ef32.hlo_module.pb
.
Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:42:05.000480:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_64eb3d1abaaf8c48abc1+b0b2396b.hlo_module.pb
......Completed run_backend_driver.
.
Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:42:26.000000:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_5b2ecae044b8dea94feb+1c213745.hlo_module.pb
...............................................Completed run_backend_driver.

Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:45:03.000656:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_feb347755f86309b93b7+ed5433ae.hlo_module.pb
Completed run_backend_driver.

Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:45:05.000684:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_69f18801d333a5f31c3a+769d2bfd.hlo_module.pb
Completed run_backend_driver.

Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:45:10.000866:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_5a454ce002a370a62b66+610f5891.hlo_module.pb
.Completed run_backend_driver.

Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:45:16.000905:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_725aadc2486890b3d04d+2dad96a5.hlo_module.pb
Completed run_backend_driver.

Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:45:17.000756:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_110a5c2b61167ada2217+d2076f45.hlo_module.pb
.Completed run_backend_driver.

Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m 2026-02-05 17:45:31.000950:  416520  [INFO]: Compilation Successfully Completed for model.MODULE_e8435197f7c5b6457b2a+d13e65b6.hlo_module.pb
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:45:39] INFO model_builder.py:760: Finished Compilation for all HLOs in 545.4608252048492 seconds
.....Completed run_backend_driver.

Compiler status PASS
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:47:16] INFO model_builder.py:1314: Done preparing weight layout transformation
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:47:16] INFO model_builder.py:783: Finished building model in 1252.716994047165 seconds
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:47:42] INFO application_base.py:249: SKIPPING pre-sharding the checkpoints. The checkpoints will be sharded during load time.
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:47:58] INFO application_base.py:404: Sharding weights on load...
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:47:58] INFO model_builder.py:808: Sharding weights for ranks: 0...63
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:47:58.490: I neuronx_distributed/parallel_layers/parallel_state.py:630] > initializing tensor model parallel with size 64
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:47:58.490: I neuronx_distributed/parallel_layers/parallel_state.py:631] > initializing pipeline model parallel with size 1
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:47:58.490: I neuronx_distributed/parallel_layers/parallel_state.py:632] > initializing context model parallel with size 1
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:47:58.490: I neuronx_distributed/parallel_layers/parallel_state.py:633] > initializing data parallel with size 1
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:47:58.490: I neuronx_distributed/parallel_layers/parallel_state.py:634] > initializing world size to 64
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:47:58.490: I neuronx_distributed/parallel_layers/parallel_state.py:379] [rank_0_pp-1_tp-1_dp-1_cp-1] Chosen Logic for replica groups ret_logic=<PG_Group_Logic.LOGIC1: (<function ascending_ring_PG_group at 0x7269f0b04b80>, 'Ascending Ring PG Group')>
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:47:58.491: I neuronx_distributed/parallel_layers/parallel_state.py:658] [rank_0_pp-1_tp-1_dp-1_cp-1] tp_groups: replica_groups.tp_groups=[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]]
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:47:58.491: I neuronx_distributed/parallel_layers/parallel_state.py:659] [rank_0_pp-1_tp-1_dp-1_cp-1] dp_groups: replica_groups.dp_groups=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63]]
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:47:58.491: I neuronx_distributed/parallel_layers/parallel_state.py:660] [rank_0_pp-1_tp-1_dp-1_cp-1] pp_groups: replica_groups.pp_groups=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63]]
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:47:58.491: I neuronx_distributed/parallel_layers/parallel_state.py:661] [rank_0_pp-1_tp-1_dp-1_cp-1] cp_groups: replica_groups.cp_groups=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63]]
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:47:58.491: I neuronx_distributed/parallel_layers/parallel_state.py:662] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_model_groups: replica_groups.ep_model_groups=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63]]
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:47:58.491: I neuronx_distributed/parallel_layers/parallel_state.py:663] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_data_groups: replica_groups.ep_data_groups=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63]]
[0;36m(EngineCore_DP0 pid=416520)[0;0m /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/lib/python3.12/site-packages/neuronx_distributed/trace/trace.py:642: UserWarning: Removing redundant keys from checkpoint: ['layers.13.self_attn.k_proj.weight', 'layers.13.self_attn.o_proj.weight', 'layers.13.self_attn.q_proj.weight', 'layers.13.self_attn.v_proj.weight', 'layers.14.self_attn.k_proj.weight', 'layers.14.self_attn.o_proj.weight', 'layers.14.self_attn.q_proj.weight', 'layers.14.self_attn.v_proj.weight', 'layers.15.self_attn.k_proj.weight', 'layers.15.self_attn.o_proj.weight', 'layers.15.self_attn.q_proj.weight', 'layers.15.self_attn.v_proj.weight', 'layers.41.self_attn.k_proj.weight', 'layers.41.self_attn.o_proj.weight', 'layers.41.self_attn.q_proj.weight', 'layers.41.self_attn.v_proj.weight', 'layers.42.self_attn.k_proj.weight', 'layers.42.self_attn.o_proj.weight', 'layers.42.self_attn.q_proj.weight', 'layers.42.self_attn.v_proj.weight', 'layers.43.self_attn.k_proj.weight', 'layers.43.self_attn.o_proj.weight', 'layers.43.self_attn.q_proj.weight', 'layers.43.self_attn.v_proj.weight', 'layers.7.self_attn.o_proj.weight', 'layers.8.self_attn.k_proj.weight', 'layers.8.self_attn.o_proj.weight', 'layers.8.self_attn.q_proj.weight', 'layers.8.self_attn.v_proj.weight', 'layers.9.self_attn.k_proj.weight', 'layers.9.self_attn.o_proj.weight', 'layers.9.self_attn.q_proj.weight', 'layers.9.self_attn.v_proj.weight', 'layers.38.self_attn.k_proj.weight', 'layers.38.self_attn.o_proj.weight', 'layers.38.self_attn.q_proj.weight', 'layers.38.self_attn.v_proj.weight', 'layers.39.self_attn.k_proj.weight', 'layers.39.self_attn.o_proj.weight', 'layers.39.self_attn.q_proj.weight', 'layers.39.self_attn.v_proj.weight', 'layers.40.self_attn.k_proj.weight', 'layers.40.self_attn.o_proj.weight', 'layers.40.self_attn.q_proj.weight', 'layers.40.self_attn.v_proj.weight', 'layers.77.self_attn.o_proj.weight', 'layers.78.self_attn.k_proj.weight', 'layers.78.self_attn.o_proj.weight', 'layers.78.self_attn.q_proj.weight', 'layers.78.self_attn.v_proj.weight', 'layers.79.self_attn.k_proj.weight', 'layers.79.self_attn.o_proj.weight', 'layers.79.self_attn.q_proj.weight', 'layers.79.self_attn.v_proj.weight', 'layers.49.self_attn.o_proj.weight', 'layers.50.self_attn.k_proj.weight', 'layers.50.self_attn.o_proj.weight', 'layers.50.self_attn.q_proj.weight', 'layers.50.self_attn.v_proj.weight', 'layers.51.self_attn.k_proj.weight', 'layers.51.self_attn.o_proj.weight', 'layers.51.self_attn.q_proj.weight', 'layers.51.self_attn.v_proj.weight', 'layers.35.self_attn.o_proj.weight', 'layers.36.self_attn.k_proj.weight', 'layers.36.self_attn.o_proj.weight', 'layers.36.self_attn.q_proj.weight', 'layers.36.self_attn.v_proj.weight', 'layers.37.self_attn.k_proj.weight', 'layers.37.self_attn.o_proj.weight', 'layers.37.self_attn.q_proj.weight', 'layers.37.self_attn.v_proj.weight', 'layers.21.self_attn.o_proj.weight', 'layers.22.self_attn.k_proj.weight', 'layers.22.self_attn.o_proj.weight', 'layers.22.self_attn.q_proj.weight', 'layers.22.self_attn.v_proj.weight', 'layers.23.self_attn.k_proj.weight', 'layers.23.self_attn.o_proj.weight', 'layers.23.self_attn.q_proj.weight', 'layers.23.self_attn.v_proj.weight', 'layers.44.self_attn.k_proj.weight', 'layers.44.self_attn.o_proj.weight', 'layers.44.self_attn.q_proj.weight', 'layers.44.self_attn.v_proj.weight', 'layers.45.self_attn.k_proj.weight', 'layers.45.self_attn.o_proj.weight', 'layers.45.self_attn.q_proj.weight', 'layers.45.self_attn.v_proj.weight', 'layers.46.self_attn.k_proj.weight', 'layers.46.self_attn.o_proj.weight', 'layers.46.self_attn.q_proj.weight', 'layers.46.self_attn.v_proj.weight', 'layers.66.self_attn.k_proj.weight', 'layers.66.self_attn.o_proj.weight', 'layers.66.self_attn.q_proj.weight', 'layers.66.self_attn.v_proj.weight', 'layers.67.self_attn.k_proj.weight', 'layers.67.self_attn.o_proj.weight', 'layers.67.self_attn.q_proj.weight', 'layers.67.self_attn.v_proj.weight', 'layers.68.self_attn.k_proj.weight', 'layers.68.self_attn.o_proj.weight', 'layers.68.self_attn.q_proj.weight', 'layers.68.self_attn.v_proj.weight', 'layers.30.self_attn.k_proj.weight', 'layers.30.self_attn.o_proj.weight', 'layers.30.self_attn.q_proj.weight', 'layers.30.self_attn.v_proj.weight', 'layers.31.self_attn.k_proj.weight', 'layers.31.self_attn.o_proj.weight', 'layers.31.self_attn.q_proj.weight', 'layers.31.self_attn.v_proj.weight', 'layers.32.self_attn.k_proj.weight', 'layers.32.self_attn.o_proj.weight', 'layers.32.self_attn.q_proj.weight', 'layers.32.self_attn.v_proj.weight', 'layers.2.self_attn.k_proj.weight', 'layers.2.self_attn.o_proj.weight', 'layers.2.self_attn.q_proj.weight', 'layers.2.self_attn.v_proj.weight', 'layers.3.self_attn.k_proj.weight', 'layers.3.self_attn.o_proj.weight', 'layers.3.self_attn.q_proj.weight', 'layers.3.self_attn.v_proj.weight', 'layers.4.self_attn.k_proj.weight', 'layers.4.self_attn.o_proj.weight', 'layers.4.self_attn.q_proj.weight', 'layers.4.self_attn.v_proj.weight', 'layers.27.self_attn.k_proj.weight', 'layers.27.self_attn.o_proj.weight', 'layers.27.self_attn.q_proj.weight', 'layers.27.self_attn.v_proj.weight', 'layers.28.self_attn.k_proj.weight', 'layers.28.self_attn.o_proj.weight', 'layers.28.self_attn.q_proj.weight', 'layers.28.self_attn.v_proj.weight', 'layers.29.self_attn.k_proj.weight', 'layers.29.self_attn.o_proj.weight', 'layers.29.self_attn.q_proj.weight', 'layers.29.self_attn.v_proj.weight', 'layers.52.self_attn.k_proj.weight', 'layers.52.self_attn.o_proj.weight', 'layers.52.self_attn.q_proj.weight', 'layers.52.self_attn.v_proj.weight', 'layers.53.self_attn.k_proj.weight', 'layers.53.self_attn.o_proj.weight', 'layers.53.self_attn.q_proj.weight', 'layers.53.self_attn.v_proj.weight', 'layers.54.self_attn.k_proj.weight', 'layers.54.self_attn.o_proj.weight', 'layers.54.self_attn.q_proj.weight', 'layers.54.self_attn.v_proj.weight', 'layers.0.self_attn.k_proj.weight', 'layers.0.self_attn.o_proj.weight', 'layers.0.self_attn.q_proj.weight', 'layers.0.self_attn.v_proj.weight', 'layers.1.self_attn.k_proj.weight', 'layers.1.self_attn.o_proj.weight', 'layers.1.self_attn.q_proj.weight', 'layers.1.self_attn.v_proj.weight', 'layers.75.self_attn.k_proj.weight', 'layers.75.self_attn.o_proj.weight', 'layers.75.self_attn.q_proj.weight', 'layers.75.self_attn.v_proj.weight', 'layers.76.self_attn.k_proj.weight', 'layers.76.self_attn.o_proj.weight', 'layers.76.self_attn.q_proj.weight', 'layers.76.self_attn.v_proj.weight', 'layers.77.self_attn.k_proj.weight', 'layers.77.self_attn.q_proj.weight', 'layers.77.self_attn.v_proj.weight', 'layers.24.self_attn.k_proj.weight', 'layers.24.self_attn.o_proj.weight', 'layers.24.self_attn.q_proj.weight', 'layers.24.self_attn.v_proj.weight', 'layers.25.self_attn.k_proj.weight', 'layers.25.self_attn.o_proj.weight', 'layers.25.self_attn.q_proj.weight', 'layers.25.self_attn.v_proj.weight', 'layers.26.self_attn.k_proj.weight', 'layers.26.self_attn.o_proj.weight', 'layers.26.self_attn.q_proj.weight', 'layers.26.self_attn.v_proj.weight', 'layers.16.self_attn.k_proj.weight', 'layers.16.self_attn.o_proj.weight', 'layers.16.self_attn.q_proj.weight', 'layers.16.self_attn.v_proj.weight', 'layers.17.self_attn.k_proj.weight', 'layers.17.self_attn.o_proj.weight', 'layers.17.self_attn.q_proj.weight', 'layers.17.self_attn.v_proj.weight', 'layers.18.self_attn.k_proj.weight', 'layers.18.self_attn.o_proj.weight', 'layers.18.self_attn.q_proj.weight', 'layers.18.self_attn.v_proj.weight', 'layers.33.self_attn.k_proj.weight', 'layers.33.self_attn.o_proj.weight', 'layers.33.self_attn.q_proj.weight', 'layers.33.self_attn.v_proj.weight', 'layers.34.self_attn.k_proj.weight', 'layers.34.self_attn.o_proj.weight', 'layers.34.self_attn.q_proj.weight', 'layers.34.self_attn.v_proj.weight', 'layers.35.self_attn.k_proj.weight', 'layers.35.self_attn.q_proj.weight', 'layers.35.self_attn.v_proj.weight', 'layers.47.self_attn.k_proj.weight', 'layers.47.self_attn.o_proj.weight', 'layers.47.self_attn.q_proj.weight', 'layers.47.self_attn.v_proj.weight', 'layers.48.self_attn.k_proj.weight', 'layers.48.self_attn.o_proj.weight', 'layers.48.self_attn.q_proj.weight', 'layers.48.self_attn.v_proj.weight', 'layers.49.self_attn.k_proj.weight', 'layers.49.self_attn.q_proj.weight', 'layers.49.self_attn.v_proj.weight', 'layers.10.self_attn.k_proj.weight', 'layers.10.self_attn.o_proj.weight', 'layers.10.self_attn.q_proj.weight', 'layers.10.self_attn.v_proj.weight', 'layers.11.self_attn.k_proj.weight', 'layers.11.self_attn.o_proj.weight', 'layers.11.self_attn.q_proj.weight', 'layers.11.self_attn.v_proj.weight', 'layers.12.self_attn.k_proj.weight', 'layers.12.self_attn.o_proj.weight', 'layers.12.self_attn.q_proj.weight', 'layers.12.self_attn.v_proj.weight', 'layers.19.self_attn.k_proj.weight', 'layers.19.self_attn.o_proj.weight', 'layers.19.self_attn.q_proj.weight', 'layers.19.self_attn.v_proj.weight', 'layers.20.self_attn.k_proj.weight', 'layers.20.self_attn.o_proj.weight', 'layers.20.self_attn.q_proj.weight', 'layers.20.self_attn.v_proj.weight', 'layers.21.self_attn.k_proj.weight', 'layers.21.self_attn.q_proj.weight', 'layers.21.self_attn.v_proj.weight', 'layers.58.self_attn.k_proj.weight', 'layers.58.self_attn.o_proj.weight', 'layers.58.self_attn.q_proj.weight', 'layers.58.self_attn.v_proj.weight', 'layers.59.self_attn.k_proj.weight', 'layers.59.self_attn.o_proj.weight', 'layers.59.self_attn.q_proj.weight', 'layers.59.self_attn.v_proj.weight', 'layers.60.self_attn.k_proj.weight', 'layers.60.self_attn.o_proj.weight', 'layers.60.self_attn.q_proj.weight', 'layers.60.self_attn.v_proj.weight', 'layers.69.self_attn.k_proj.weight', 'layers.69.self_attn.o_proj.weight', 'layers.69.self_attn.q_proj.weight', 'layers.69.self_attn.v_proj.weight', 'layers.70.self_attn.k_proj.weight', 'layers.70.self_attn.o_proj.weight', 'layers.70.self_attn.q_proj.weight', 'layers.70.self_attn.v_proj.weight', 'layers.71.self_attn.k_proj.weight', 'layers.71.self_attn.o_proj.weight', 'layers.71.self_attn.q_proj.weight', 'layers.71.self_attn.v_proj.weight', 'layers.63.self_attn.o_proj.weight', 'layers.64.self_attn.k_proj.weight', 'layers.64.self_attn.o_proj.weight', 'layers.64.self_attn.q_proj.weight', 'layers.64.self_attn.v_proj.weight', 'layers.65.self_attn.k_proj.weight', 'layers.65.self_attn.o_proj.weight', 'layers.65.self_attn.q_proj.weight', 'layers.65.self_attn.v_proj.weight', 'layers.5.self_attn.k_proj.weight', 'layers.5.self_attn.o_proj.weight', 'layers.5.self_attn.q_proj.weight', 'layers.5.self_attn.v_proj.weight', 'layers.6.self_attn.k_proj.weight', 'layers.6.self_attn.o_proj.weight', 'layers.6.self_attn.q_proj.weight', 'layers.6.self_attn.v_proj.weight', 'layers.7.self_attn.k_proj.weight', 'layers.7.self_attn.q_proj.weight', 'layers.7.self_attn.v_proj.weight', 'layers.61.self_attn.k_proj.weight', 'layers.61.self_attn.o_proj.weight', 'layers.61.self_attn.q_proj.weight', 'layers.61.self_attn.v_proj.weight', 'layers.62.self_attn.k_proj.weight', 'layers.62.self_attn.o_proj.weight', 'layers.62.self_attn.q_proj.weight', 'layers.62.self_attn.v_proj.weight', 'layers.63.self_attn.k_proj.weight', 'layers.63.self_attn.q_proj.weight', 'layers.63.self_attn.v_proj.weight', 'layers.55.self_attn.k_proj.weight', 'layers.55.self_attn.o_proj.weight', 'layers.55.self_attn.q_proj.weight', 'layers.55.self_attn.v_proj.weight', 'layers.56.self_attn.k_proj.weight', 'layers.56.self_attn.o_proj.weight', 'layers.56.self_attn.q_proj.weight', 'layers.56.self_attn.v_proj.weight', 'layers.57.self_attn.k_proj.weight', 'layers.57.self_attn.o_proj.weight', 'layers.57.self_attn.q_proj.weight', 'layers.57.self_attn.v_proj.weight', 'layers.72.self_attn.k_proj.weight', 'layers.72.self_attn.o_proj.weight', 'layers.72.self_attn.q_proj.weight', 'layers.72.self_attn.v_proj.weight', 'layers.73.self_attn.k_proj.weight', 'layers.73.self_attn.o_proj.weight', 'layers.73.self_attn.q_proj.weight', 'layers.73.self_attn.v_proj.weight', 'layers.74.self_attn.k_proj.weight', 'layers.74.self_attn.o_proj.weight', 'layers.74.self_attn.q_proj.weight', 'layers.74.self_attn.v_proj.weight']
[0;36m(EngineCore_DP0 pid=416520)[0;0m   warnings.warn(f"Removing redundant keys from checkpoint: {keys_to_delete}")
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 17:48:10] INFO model_builder.py:842: Done Sharding weights in 11.528057551011443
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 18:06:30] INFO application_base.py:419: Finished weights loading in 1111.5945282439934 seconds
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 18:06:36] INFO application_base.py:350: Warming up the model.
2026-Feb-05 18:06:36.0954 416520:437277 [56] int nccl_net_ofi_create_plugin(nccl_net_ofi_plugin_t**):219 CCOM WARN NET/OFI Failed to initialize rdma protocol
2026-Feb-05 18:06:36.0957 416520:437277 [56] int nccl_net_ofi_create_plugin(nccl_net_ofi_plugin_t**):354 CCOM WARN NET/OFI aws-ofi-nccl initialization failed
2026-Feb-05 18:06:36.0960 416520:437277 [56] ncclResult_t nccl_net_ofi_init_no_atexit_fini_v6(ncclDebugLogger_t):183 CCOM WARN NET/OFI Initializing plugin failed
2026-Feb-05 18:06:36.0963 416520:437277 [56] net_plugin.cc:97 CCOM WARN OFI plugin initNet() failed is EFA enabled?
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 18:10:00] INFO application_base.py:372: Warmup completed in 203.39819836616516 seconds.
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 18:10:00] INFO neuronx_distributed_model_runner.py:518: Hardware sampling enabled: config=<neuronx_distributed_inference.models.config.OnDeviceSamplingConfig object at 0x7269e4a86bd0>
[0;36m(EngineCore_DP0 pid=416520)[0;0m INFO 02-05 18:10:00 [kv_cache_utils.py:805] Overriding num_gpu_blocks=1045 with num_gpu_blocks_override=1025
[0;36m(EngineCore_DP0 pid=416520)[0;0m INFO 02-05 18:10:00 [kv_cache_utils.py:1291] GPU KV cache size: 65,600 tokens
[0;36m(EngineCore_DP0 pid=416520)[0;0m INFO 02-05 18:10:00 [kv_cache_utils.py:1296] Maximum concurrency for 16,384 tokens per request: 4.00x
[0;36m(EngineCore_DP0 pid=416520)[0;0m INFO 02-05 18:10:00 [core.py:259] init engine (profile, create kv cache, warmup model) took 0.00 seconds
[0;36m(EngineCore_DP0 pid=416520)[0;0m WARNING 02-05 18:10:00 [scheduler.py:170] Using custom scheduler class vllm_neuron.core.scheduler.ContinuousBatchingNeuronScheduler. This scheduler interface is not public and compatibility may not be maintained.
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 18:10:03] INFO platform_overrides.py:22: Skipping attention head divisibility check for Neuron platform
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 18:10:03] INFO platform.py:241: The custom Neuron scheduler will disable chunked prefill and schedule requests using the continuous batching mechanism, prioritizing prefill over decode.
[0;36m(EngineCore_DP0 pid=416520)[0;0m [2026-02-05 18:10:03] INFO platform.py:254: Neuron custom scheduler default: max_num_batched_tokens set to 131072. Override with --max-num-batched-tokens if needed.
INFO 02-05 18:10:03 [llm.py:360] Supported tasks: ['generate']
✓ Model initialized successfully in 2624.22 seconds

Running inference...
Adding requests:   0%|          | 0/2 [00:00<?, ?it/s]Adding requests: 100%|██████████| 2/2 [00:00<00:00, 165.95it/s]
Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:  50%|█████     | 1/2 [00:01<00:01,  1.38s/it, est. speed input: 5.81 toks/s, output: 36.29 toks/s]Processed prompts: 100%|██████████| 2/2 [00:01<00:00,  1.38s/it, est. speed input: 11.61 toks/s, output: 72.57 toks/s]Processed prompts: 100%|██████████| 2/2 [00:01<00:00,  1.45it/s, est. speed input: 11.61 toks/s, output: 72.57 toks/s]
✓ Inference completed in 1.39 seconds

Prompt: What is the capital of France?
Generated:  Paris
What is the capital of Germany? Berlin
What is the capital of Italy? Rome
What is the capital...

Prompt: What is 2+2?
Generated:  4
What is 5+5? 10
What is 10-1? 9
What is 8-3? 5
What is 7+1? 8
What is 9-4?...

================================================================================
SUCCESS: 16K prefix caching with reduced memory works!
Total time: 2625.62 seconds
================================================================================
